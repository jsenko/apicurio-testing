= Migration Guide Analysis and Recommendations
:toc: left
:toclevels: 3
:sectnums:

== Executive Summary

This document provides a comprehensive analysis of the Apicurio Registry migration guide (`migration.adoc`) compared
to the four automated migration test scenarios. The analysis identifies critical gaps, missing procedures, and areas
for improvement to ensure customers can successfully migrate from Registry 2.6.x to 3.1.x.

*Overall Assessment:* The migration guide is well-structured but **missing several critical operational procedures**
that are clearly demonstrated in the test scenarios. The scenarios reveal important migration patterns not documented
in the guide, particularly around **downtime management, pre/post validation, traffic switching, and authentication
handling**.

*Impact:* Without these additions, customers may experience:

* Unnecessary downtime during migration
* Failed migrations due to missing validation steps
* Authentication errors during export/import
* Confusion about KafkaSQL storage migration
* Inability to validate backward compatibility
* No clear rollback strategy

== Analysis Methodology

This analysis compared:

* **Source Document:** `migration-testing/docs/migration.adoc` (current migration guide)
* **Test Scenario 1:** Basic PostgreSQL migration with nginx traffic switching
* **Test Scenario 2:** KafkaSQL storage migration with Kafka producer/consumer applications
* **Test Scenario 3:** PostgreSQL migration with TLS/HTTPS configuration
* **Test Scenario 4:** Comprehensive migration with PostgreSQL, TLS, OAuth2, and Kafka applications

Each scenario was analyzed for:

1. Migration procedures and workflow
2. Configuration differences between v2 and v3
3. Validation and testing approaches
4. Downtime management strategies
5. Client application migration patterns

== Critical Gaps Identified

=== Gap 1: Missing Downtime and Traffic Management Strategy

==== What the Scenarios Demonstrate

All four scenarios follow a consistent pattern for minimizing downtime:

1. Deploy Registry v2 with database/storage
2. Deploy nginx reverse proxy/load balancer routing to v2
3. Create and validate test data
4. Export data from v2 (registry remains operational)
5. Deploy Registry v3 with separate database/storage
6. Import data into v3 (v2 still handling traffic)
7. **Switch nginx to route to v3** (downtime: ~30 seconds)
8. Validate v3 with backward compatibility tests
9. Keep v2 running for potential rollback

*Key Insight:* Both v2 and v3 run simultaneously for a period, with nginx managing the traffic cutover. This enables
minimal downtime (only during the nginx switch).

==== What the Guide Currently Says

From `migration.adoc` lines 9-10:
[source]
----
Because of the breaking changes in 3.x, there is no in-place upgrade. You must stand up a new 3.x deployment,
migrate the persisted content, and update your client applications and automation.
----

*Problems:*

* "Stand up a new 3.x deployment" is vague
* No mention of load balancers, reverse proxies, or traffic routing
* No downtime expectations or minimization strategies
* Implies sequential approach (shutdown v2, deploy v3) rather than parallel

==== Recommendation

Add a new section titled **"Minimizing Downtime During Migration"** immediately after the introduction:

[source,asciidoc]
----
== Minimizing Downtime During Migration

The migration from Registry 2.x to 3.x can be performed with minimal downtime (typically less than 1 minute) by
using a reverse proxy or load balancer to manage traffic routing.

=== Recommended Architecture

[literal]
....
┌─────────────────────────────────────────────────────────────┐
│                     Client Applications                      │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ↓
                    ┌───────────────┐
                    │ Load Balancer │  (nginx, HAProxy, etc.)
                    │  (Port 8080)  │
                    └───────┬───────┘
                            │
        ┌───────────────────┼───────────────────┐
        │ (initially)       │      (after)      │
        ↓                   ↓                   ↓
┌───────────────┐   ┌───────────────┐   ┌───────────────┐
│  Registry 2.x │   │  Registry 2.x │   │  Registry 3.x │
│   + Database  │   │   + Database  │   │   + Database  │
└───────────────┘   └───────────────┘   └───────────────┘
    (Port 2222)         (Port 2222)         (Port 3333)
....

=== Migration Phases

.Phase 1: Preparation (Zero Downtime)
1. If not already using a load balancer, deploy nginx/HAProxy in front of existing v2 registry
2. Update client applications to connect through load balancer
3. Verify all traffic flows correctly through load balancer

.Phase 2: Parallel Deployment (Zero Downtime)
1. Deploy Registry 3.x infrastructure (database, Kafka if applicable)
2. Deploy Registry 3.x server on different port (not yet receiving traffic)
3. Export data from v2 registry (read-only operation, no impact on v2)
4. Import data into v3 registry
5. Validate v3 registry has all data

.Phase 3: Traffic Switch (Downtime: ~30 seconds)
1. Update load balancer configuration to route to v3
2. Reload/restart load balancer
3. Monitor logs for errors

.Phase 4: Validation and Rollback Capability (Zero Downtime)
1. Test applications work correctly with v3
2. Keep v2 running for 1-7 days for quick rollback if needed
3. After validation period, decommission v2

=== Example: nginx Configuration

*Initial configuration (routing to v2):*
[source,nginx]
----
upstream registry {
    server registry-v2:8080;
}

server {
    listen 8080;
    location / {
        proxy_pass http://registry;
    }
}
----

*After migration (routing to v3):*
[source,nginx]
----
upstream registry {
    server registry-v3:8080;
}

server {
    listen 8080;
    location / {
        proxy_pass http://registry;
    }
}
----

=== Downtime Expectations

[cols="1,2,1",options="header"]
|===
| Phase | Operations | Downtime

| Export from v2
| Read-only operation
| Zero

| Deploy v3
| Parallel to v2
| Zero

| Import into v3
| Isolated to v3
| Zero

| Switch load balancer
| Configuration reload
| 10-30 seconds

| Validation
| Both registries available
| Zero (rollback possible)
|===
----

=== Gap 2: Missing Read-Only Mode Strategy During Export

==== What Production Deployments Need

A critical best practice for production migrations is to prevent data changes during the export process. This ensures:

* Export contains a complete, consistent snapshot
* No artifacts are added after export
* No versions are created during export
* Import into v3 contains 100% of v2 data (not 99.9%)

==== The Challenge

Registry 2.x **does not have a built-in read-only mode**. The server cannot be configured to reject write operations
while continuing to serve read requests.

==== The Solution: Load Balancer Write Blocking

Use the load balancer (nginx, HAProxy, etc.) to enforce read-only mode at the traffic layer by blocking HTTP methods
that modify data:

* **Block:** POST, PUT, PATCH, DELETE
* **Allow:** GET, HEAD, OPTIONS

This prevents:

* New artifact registration
* Version uploads
* Metadata updates
* Rule changes
* Artifact/version deletion

==== Implementation with nginx

*nginx configuration for read-only mode:*

[source,nginx]
----
upstream registry {
    server registry-v2:8080;
}

server {
    listen 8080;

    location / {
        # Block write operations during export
        if ($request_method !~ ^(GET|HEAD|OPTIONS)$) {
            return 405 "Registry is in read-only mode for migration";
        }

        proxy_pass http://registry;
        proxy_set_header Host $host;
        proxy_set_header X-Read-Only-Mode "true";
    }

    # Allow health checks
    location /health {
        proxy_pass http://registry;
    }
}
----

*Alternative: Temporary read-only configuration:*

[source,nginx]
----
# Create separate config file: nginx-readonly.conf
map $request_method $readonly_mode {
    default         "blocked";
    GET             "allowed";
    HEAD            "allowed";
    OPTIONS         "allowed";
}

server {
    listen 8080;

    location / {
        if ($readonly_mode = "blocked") {
            return 405 "Registry temporarily in read-only mode";
        }

        proxy_pass http://registry-v2:8080;
    }
}
----

==== Migration Workflow with Read-Only Mode

The recommended workflow becomes:

1. **Pre-export phase:** v2 registry operational (read/write)
2. **Switch to read-only mode:** Update nginx config, reload nginx
3. **Export data:** Export from v2 (guaranteed complete snapshot)
4. **Deploy and import v3:** While v2 still serves read requests
5. **Switch to v3:** Update nginx to route to v3 (read/write enabled)
6. **Validate:** Ensure 100% data preservation

*Timeline:*

[literal]
....
Time    v2 Registry     nginx           Client Impact
────────────────────────────────────────────────────────────
T-30m   Read/Write      → v2 (R/W)      Normal operation
T-5m    Read/Write      → v2 (R/O)      Reads work, writes blocked (405)
T-0m    Export starts   → v2 (R/O)      Reads work, writes blocked
T+10m   Export done     → v2 (R/O)      Reads work, writes blocked
T+20m   v3 deployed     → v2 (R/O)      Reads work, writes blocked
T+25m   Import done     → v2 (R/O)      Reads work, writes blocked
T+30m   v3 validated    → v3 (R/W)      Normal operation on v3
....
----

*Write operation downtime:* 30-35 minutes (during export and import)
*Read operation downtime:* 30 seconds (during nginx switch)
*Data consistency:* 100% guaranteed

==== Client Application Behavior

During read-only mode, client applications will experience:

*Kafka SerDes with auto-register:*
[source]
----
[ERROR] Failed to register schema: HTTP 405 Registry is in read-only mode
----

*REST API calls:*
[source,bash]
----
$ curl -X POST http://registry/apis/registry/v2/groups/default/artifacts \
    -H "Content-Type: application/json" \
    -d @schema.json

HTTP/1.1 405 Method Not Allowed
Registry is in read-only mode for migration
----

*Recommendation:*

* Schedule migration during low-activity period
* Communicate read-only window to stakeholders
* Temporarily disable applications that require schema registration
* Plan for write operations to resume after v3 switch

==== nginx Configuration Management

*Prepare configurations in advance:*

[source,bash]
----
# Directory structure
nginx/
├── nginx.conf                    # Base nginx config
├── conf.d/
│   ├── registry-v2-readwrite.conf   # Normal v2 operations
│   ├── registry-v2-readonly.conf    # Read-only mode for export
│   └── registry-v3-readwrite.conf   # v3 after migration
----

*Switch to read-only mode:*

[source,bash]
----
# Stop nginx container
docker compose -f docker-compose-nginx.yml down

# Start with read-only config
docker compose -f docker-compose-nginx-readonly.yml up -d

# Or reload config without downtime
docker exec nginx cp /configs/registry-v2-readonly.conf /etc/nginx/conf.d/default.conf
docker exec nginx nginx -s reload

# Verify read-only mode
curl -X POST http://load-balancer:8080/apis/registry/v2/groups/default/artifacts
# Should return: 405 Method Not Allowed
----

*Perform export:*

[source,bash]
----
# Export while nginx blocks writes
curl -X GET "http://registry-v2:8080/apis/registry/v2/admin/export" \
  -H "Authorization: Bearer $TOKEN" \
  -o registry-export.zip

# Note: Access registry directly (bypass nginx) for admin operations
----

*Switch to v3 (read/write):*

[source,bash]
----
# Update nginx to route to v3
docker compose -f docker-compose-nginx-v3.yml up -d

# Verify writes work
curl -X POST http://load-balancer:8080/apis/registry/v3/groups/default/artifacts \
  -H "Content-Type: application/json" \
  -d @test-schema.json
# Should succeed with HTTP 200/201
----

==== Alternative: Scheduled Maintenance Window

If blocking writes is unacceptable, consider a traditional maintenance window:

1. Announce scheduled downtime (e.g., 1 hour window)
2. Stop all client applications
3. Export from v2
4. Deploy and import to v3
5. Switch nginx to v3
6. Resume client applications

*Trade-off:* Longer total downtime but simpler coordination.

==== What the Guide Currently Says

The guide mentions that export is a "read-only operation" but doesn't address:

* Preventing concurrent writes during export
* Ensuring export contains 100% of data
* Load balancer-based write blocking
* Client impact during read-only period

==== Recommendation

Add a new section **"Ensuring Data Consistency During Export"** that covers:

1. Why preventing writes during export is important
2. How to configure nginx for read-only mode
3. Migration timeline with read-only window
4. Expected client application behavior
5. nginx configuration examples
6. Validation that read-only mode is active

This should be added to both the "Minimizing Downtime" section and the detailed workflow section.

=== Gap 3: Missing Pre-Migration and Post-Migration Validation

==== What the Scenarios Demonstrate

All scenarios implement comprehensive validation:

*Pre-Migration Validation (e.g., scenario-1/scripts/step-D-validate-pre-migration.sh):*

1. Build artifact-validator-v2 application
2. Run validator against v2 registry
3. Record baseline metrics:
   - Total artifact count (25 expected)
   - Total version count (76 expected)
   - Artifact types distribution
   - Rules configuration
   - Metadata (labels, descriptions)
4. Save validation report for comparison
5. Exit with error if validation fails

*Post-Migration Validation (e.g., scenario-1/scripts/step-J-validate-post-migration.sh):*

1. Run v2 validator against v3 registry (backward compatibility test)
2. Compare results to pre-migration baseline
3. Verify all artifacts, versions, metadata preserved

*Native v3 Validation (e.g., scenario-1/scripts/step-K-validate-v3-native.sh):*

1. Run v3 validator using native v3 API
2. Test v3-specific features (branches, new search endpoints)
3. Verify v3 functionality works correctly

==== What the Guide Currently Says

From `migration.adoc` lines 69-86:

[source]
----
. Validate the migrated content. Compare artifact counts between the legacy and new deployments:
+
[source,bash,subs="attributes+"]
----
curl "http://old-registry.my-company.com/apis/registry/v2/search/artifacts"
----
+
[source,bash,subs="attributes+"]
----
curl "http://new-registry.my-company.com/apis/registry/v3/search/artifacts"
----
+
Check that global rules were imported successfully:
+
[source,bash,subs="attributes+"]
----
curl "http://new-registry.my-company.com/apis/registry/v3/admin/rules"
----
----

*Problems:*

* Only mentions artifact count comparison (too basic)
* No structured validation process
* No pre-migration baseline capture
* No backward compatibility verification
* No guidance on what to validate beyond counts

==== Recommendation

Replace the current validation step with a comprehensive section:

[source,asciidoc]
----
=== Validating the Migration

Thorough validation is critical to ensure a successful migration. Follow this structured approach:

==== Pre-Migration Validation

Before exporting data, capture a baseline of your v2 registry state:

[source,bash]
----
# 1. Record total artifact count
ARTIFACT_COUNT=$(curl -s "http://old-registry.my-company.com/apis/registry/v2/search/artifacts" \
  | jq '.count')
echo "Total artifacts: $ARTIFACT_COUNT" > migration-baseline.txt

# 2. Record artifact breakdown by type
curl -s "http://old-registry.my-company.com/apis/registry/v2/search/artifacts?limit=1000" \
  | jq -r '.artifacts[] | .type' | sort | uniq -c >> migration-baseline.txt

# 3. Export global rules configuration
curl -s "http://old-registry.my-company.com/apis/registry/v2/admin/rules" \
  > global-rules-backup.json

# 4. Sample 10 artifacts for detailed comparison
curl -s "http://old-registry.my-company.com/apis/registry/v2/search/artifacts?limit=10" \
  | jq '.artifacts[] | {id: .id, type: .type, name: .name}' \
  > sample-artifacts.json
----

Save all baseline files for post-migration comparison.

==== Post-Migration Validation

After importing data into v3, perform these validation checks:

===== Step 1: Verify Artifact Count

[source,bash]
----
# Check artifact count in v3
V3_COUNT=$(curl -s "http://new-registry.my-company.com/apis/registry/v3/search/artifacts" \
  | jq '.count')

if [ "$V3_COUNT" -eq "$ARTIFACT_COUNT" ]; then
    echo "✓ Artifact count matches: $V3_COUNT"
else
    echo "✗ Artifact count mismatch! v2: $ARTIFACT_COUNT, v3: $V3_COUNT"
    exit 1
fi
----

===== Step 2: Verify Global Rules

[source,bash]
----
# Compare global rules
curl -s "http://new-registry.my-company.com/apis/registry/v3/admin/rules" \
  > global-rules-v3.json

# Compare with backup (requires manual review or diff tool)
diff global-rules-backup.json global-rules-v3.json
----

===== Step 3: Test Backward Compatibility

Verify that v2 clients can access the v3 registry:

[source,bash]
----
# Test v2 API endpoint on v3 registry
curl -s "http://new-registry.my-company.com/apis/registry/v2/search/artifacts?limit=10" \
  | jq '.artifacts[] | {id: .id, type: .type}'

# Should return valid results without errors
----

===== Step 4: Verify Metadata Preservation

Check that metadata (labels, descriptions, etc.) survived migration:

[source,bash]
----
# Compare sample artifacts metadata
for artifactId in $(jq -r '.[].id' sample-artifacts.json); do
    echo "Checking artifact: $artifactId"

    # Get artifact details from v3
    curl -s "http://new-registry.my-company.com/apis/registry/v3/groups/default/artifacts/$artifactId" \
      | jq '{name, description, labels}'
done
----

===== Step 5: Test v3 Native Functionality

Verify v3-specific features work correctly:

[source,bash]
----
# Test new v3 search endpoints
curl -s "http://new-registry.my-company.com/apis/registry/v3/search/groups"
curl -s "http://new-registry.my-company.com/apis/registry/v3/search/versions?groupId=default&limit=10"

# Test branch functionality (v3 feature)
curl -s "http://new-registry.my-company.com/apis/registry/v3/groups/default/artifacts/example/branches"
----

==== Validation Checklist

Use this checklist to ensure complete validation:

[cols="1,3,1",options="header"]
|===
| Check | Description | Status

| Artifact Count
| Total artifacts match between v2 and v3
| ☐

| Version Count
| Total versions match (check sample artifacts)
| ☐

| Global Rules
| All global rules imported correctly
| ☐

| Artifact Rules
| Sample artifact-specific rules preserved
| ☐

| Metadata
| Labels, descriptions, properties intact
| ☐

| References
| Artifact references preserved
| ☐

| v2 API Compatibility
| v2 API endpoints work on v3
| ☐

| v3 Native Features
| New v3 endpoints functional
| ☐

| Client Applications
| Sample client apps work correctly
| ☐
|===

==== What to Do If Validation Fails

If any validation check fails:

1. *Do not switch production traffic to v3*
2. Review import logs for errors
3. Check v3 server logs for issues
4. Compare specific failed artifacts between v2 and v3
5. If needed, drop v3 database and re-attempt import
6. Contact support if issues persist

The v2 registry remains operational throughout validation, enabling safe troubleshooting.
----

=== Gap 3: Missing Authentication Configuration During Migration

==== What Scenario 4 Demonstrates

Scenario 4 shows complete OAuth2/OIDC authentication throughout the migration:

*Keycloak Configuration:*

* Realm: `registry`
* Client for API: `registry-api`
* Client for developers: `developer-client`
* Roles: `sr-admin`, `sr-developer`, `sr-readonly`

*Export Script (scenario-4/scripts/step-J-export-v2-data.sh):*

[source,bash]
----
# Get OAuth2 access token from Keycloak
TOKEN_RESPONSE=$(curl -k -s -X POST "$TOKEN_ENDPOINT" \
    -H "Content-Type: application/x-www-form-urlencoded" \
    -d "grant_type=client_credentials" \
    -d "client_id=$CLIENT_ID" \
    -d "client_secret=$CLIENT_SECRET")

ACCESS_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.access_token')

# Export with authentication
curl -w "%{http_code}" -o "$EXPORT_FILE" -s -k \
    -H "Authorization: Bearer $ACCESS_TOKEN" \
    "$EXPORT_ENDPOINT"
----

*Import Script (scenario-4/scripts/step-L-import-v3-data.sh):*

Uses the same authentication pattern for import into v3.

==== What the Guide Currently Says

From `migration.adoc` lines 46-48:

[source]
----
.Prerequisites
* Running {registry} instances of the {registry-v2} server you are exporting from and the 3.x server you are
  importing into.
* Administrative credentials that allow access to the `/apis/registry/v2/admin/export` and
  `/apis/registry/v3/admin/import` endpoints.
----

From lines 52-67, the export/import examples show **unauthenticated** curl commands.

*Problems:*

* Prerequisites mention "administrative credentials" but never use them
* Export/import examples are unauthenticated (will fail on secured deployments)
* No guidance on obtaining OAuth2 tokens
* No mention that export/import require authentication in secured deployments

==== Recommendation

Update the export/import procedure to include authentication:

[source,asciidoc]
----
=== Exporting and Importing with Authentication

If your Registry deployment uses OAuth2/OIDC authentication (recommended for production), you must obtain an access
token before calling the admin export and import endpoints.

==== Obtaining an OAuth2 Access Token

[source,bash]
----
# Configuration
KEYCLOAK_URL="https://keycloak.example.com"
REALM="registry"
CLIENT_ID="admin-client"
CLIENT_SECRET="your-client-secret"

# Get access token
TOKEN_RESPONSE=$(curl -X POST \
  "$KEYCLOAK_URL/realms/$REALM/protocol/openid-connect/token" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "grant_type=client_credentials" \
  -d "client_id=$CLIENT_ID" \
  -d "client_secret=$CLIENT_SECRET")

# Extract access token
ACCESS_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.access_token')

# Verify token was obtained
if [ -z "$ACCESS_TOKEN" ] || [ "$ACCESS_TOKEN" = "null" ]; then
    echo "Failed to obtain access token"
    exit 1
fi
----

*Note:* The client must have appropriate roles (e.g., `sr-admin`) to access admin endpoints.

==== Export with Authentication

[source,bash]
----
curl -X GET "https://old-registry.my-company.com/apis/registry/v2/admin/export" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -o registry-export.zip

# Verify export succeeded
if [ -f registry-export.zip ] && [ -s registry-export.zip ]; then
    echo "Export successful: $(ls -lh registry-export.zip | awk '{print $5}')"
else
    echo "Export failed"
    exit 1
fi
----

==== Import with Authentication

[source,bash]
----
curl -X POST "https://new-registry.my-company.com/apis/registry/v3/admin/import" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -H "Content-Type: application/zip" \
  --data-binary @registry-export.zip

# Check HTTP response code (200 or 204 indicates success)
----

==== Unauthenticated Deployments

If your Registry deployment does not use authentication, you can omit the `Authorization` header:

[source,bash]
----
# Export (unauthenticated)
curl -X GET "http://old-registry.my-company.com/apis/registry/v2/admin/export" \
  -o registry-export.zip

# Import (unauthenticated)
curl -X POST "http://new-registry.my-company.com/apis/registry/v3/admin/import" \
  -H "Content-Type: application/zip" \
  --data-binary @registry-export.zip
----

*Security Note:* Unauthenticated deployments are not recommended for production use.
----

=== Gap 4: Missing KafkaSQL Storage Migration Details

==== What Scenario 2 Demonstrates

Scenario 2 provides critical insights about KafkaSQL storage migration:

*v2 Configuration (scenario-2/docker-compose-v2-kafka.yml):*

[source,yaml]
----
environment:
  KAFKA_BOOTSTRAP_SERVERS: scenario2-kafka:29092
  REGISTRY_KAFKASQL_TOPIC: kafkasql-journal-v2  # v2-specific topic
  REGISTRY_KAFKASQL_CONSUMER_GROUP_ID: registry-v2-consumer
----

*v3 Configuration (scenario-2/docker-compose-v3-kafka.yml):*

[source,yaml]
----
environment:
  APICURIO_STORAGE_KIND: kafkasql
  APICURIO_KAFKASQL_BOOTSTRAP_SERVERS: scenario2-kafka:29092
  APICURIO_KAFKASQL_TOPIC: kafkasql-journal-v3  # v3-specific topic (DIFFERENT!)
----

*Key Insights:*

1. Both registries can use the **same Kafka cluster**
2. They **must use different topics** for their journals
3. v3 **cannot read v2's Kafka journal** directly
4. Export/import is **required** (not optional) for KafkaSQL migration
5. The v2 topic can be deleted after successful migration

==== What the Guide Currently Says

From `migration.adoc` lines 29-31:

[source]
----
== Re-engineered Kafka storage variant
The KafkaSQL storage implementation is now optimized for stability and maintainability.
The new design reduces startup times for large installations.
----

From lines 204-228, the configuration section mentions KafkaSQL properties but doesn't explain the migration process.

*Problems:*

* No specific guidance for KafkaSQL migration
* Doesn't clarify that export/import is REQUIRED (not optional)
* Doesn't mention that v3 cannot read v2's journal
* Doesn't explain that both can share the same Kafka cluster
* Missing guidance on topic naming and cleanup

==== Recommendation

Add a new subsection under "Migrating Registry Data":

[source,asciidoc]
----
=== Migrating KafkaSQL Storage Deployments

If your Registry 2.x deployment uses KafkaSQL storage, pay special attention to these requirements:

==== Critical: Export/Import is Required

Registry 3.x uses a redesigned KafkaSQL implementation and **cannot directly read the v2 Kafka journal**. You
MUST use the export/import process to migrate data, even though both versions use Kafka for storage.

*Do not attempt to:*

* Point v3 to the v2 KafkaSQL topic
* Migrate the Kafka topic data directly
* Use Kafka tools to copy/transform the journal

The export/import API is the only supported migration path.

==== Kafka Cluster Reuse

Both Registry v2 and v3 can use the **same Kafka cluster** during migration. Use different topic names to avoid
conflicts:

[source,properties]
----
# Registry 2.x configuration
KAFKA_BOOTSTRAP_SERVERS=kafka.example.com:9092
REGISTRY_KAFKASQL_TOPIC=kafkasql-journal-v2
REGISTRY_KAFKASQL_CONSUMER_GROUP_ID=registry-v2-consumer

# Registry 3.x configuration (same Kafka cluster, different topic)
APICURIO_STORAGE_KIND=kafkasql
APICURIO_KAFKASQL_BOOTSTRAP_SERVERS=kafka.example.com:9092
APICURIO_KAFKASQL_TOPIC=kafkasql-journal-v3
----

==== KafkaSQL Migration Procedure

Follow this process for KafkaSQL deployments:

.Phase 1: Preparation
1. Verify v2 registry is healthy and using KafkaSQL storage
2. Note the current KafkaSQL topic name (usually `kafkasql-journal`)
3. Choose a new topic name for v3 (e.g., `kafkasql-journal-v3`)

.Phase 2: Deploy v3 Registry
1. Deploy v3 registry pointing to the same Kafka cluster
2. Configure v3 with a **different topic name**
3. v3 will auto-create its topic (if auto-create enabled)
4. Verify v3 starts successfully (will be empty initially)

.Phase 3: Data Migration
1. Export data from v2 using the admin API
2. Import data into v3 using the admin API
3. Validate artifact counts match

.Phase 4: Traffic Switch
1. Switch clients to use v3 registry
2. Monitor for errors

.Phase 5: Cleanup (After Validation)
1. Keep v2 running for 1-7 days for rollback capability
2. After validation period, shut down v2 registry
3. Optionally delete the v2 KafkaSQL topic to reclaim space:

[source,bash]
----
# List topics to confirm the v2 topic name
kafka-topics.sh --bootstrap-server kafka:9092 --list | grep kafkasql

# Delete v2 topic (ONLY after successful migration and validation)
kafka-topics.sh --bootstrap-server kafka:9092 \
  --delete --topic kafkasql-journal-v2
----

==== Configuration Differences

[cols="1,1,1",options="header"]
|===
| Configuration | Registry 2.x | Registry 3.x

| Storage kind
| (implicit)
| `APICURIO_STORAGE_KIND=kafkasql`

| Bootstrap servers
| `KAFKA_BOOTSTRAP_SERVERS`
| `APICURIO_KAFKASQL_BOOTSTRAP_SERVERS`

| Topic name
| `REGISTRY_KAFKASQL_TOPIC`
| `APICURIO_KAFKASQL_TOPIC`

| Topic auto-create
| `REGISTRY_KAFKASQL_TOPIC_AUTO_CREATE`
| `APICURIO_KAFKASQL_TOPIC_AUTO_CREATE`

| Consumer group
| `REGISTRY_KAFKASQL_CONSUMER_GROUP_ID`
| (auto-generated)
|===

==== Troubleshooting KafkaSQL Migration

*Problem:* v3 registry fails to start with "topic not found" error

* *Solution:* Enable topic auto-creation or manually create the topic:

[source,bash]
----
kafka-topics.sh --bootstrap-server kafka:9092 \
  --create --topic kafkasql-journal-v3 \
  --partitions 1 --replication-factor 3
----

*Problem:* Import into v3 succeeded but no data visible

* *Solution:* Check v3 is reading from the correct topic. Verify `APICURIO_KAFKASQL_TOPIC` configuration.

*Problem:* v2 and v3 seem to be interfering with each other

* *Solution:* Verify they are using **different topic names**. Check Kafka consumer groups.
----

=== Gap 5: Missing TLS/HTTPS Configuration During Migration

==== What Scenarios 3 & 4 Demonstrate

Both scenarios 3 and 4 show comprehensive TLS configuration:

*Certificate Generation (scenario-3/scripts/generate-certs.sh):*

* Creates self-signed certificates for testing
* Generates PKCS12 keystore for servers
* Generates JKS truststore for clients
* Includes SAN entries for all hostnames

*Server Configuration (identical for v2 and v3):*

[source,yaml]
----
QUARKUS_HTTP_SSL_PORT: 8443
QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_FILE: /certs/registry-keystore.p12
QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_PASSWORD: registry123
QUARKUS_HTTP_INSECURE_REQUESTS: disabled
----

*Client Configuration Differences:*

v2 Client (system properties):
[source,java]
----
System.setProperty("javax.net.ssl.trustStore", "certs/registry-truststore.jks");
System.setProperty("javax.net.ssl.trustStorePassword", "registry123");
RegistryClient client = RegistryClientFactory.create(registryUrl);
----

v3 Client (RegistryClientOptions API):
[source,java]
----
RegistryClientOptions options = RegistryClientOptions.create(registryUrl)
    .trustStoreJks("certs/registry-truststore.jks", "registry123");
RegistryClient client = RegistryClientFactory.create(options);
----

==== What the Guide Currently Says

The configuration section (lines 147-287) mentions TLS properties but:

* No guidance on TLS during migration process
* No explanation that server TLS config is identical (good news!)
* Client TLS configuration differences not highlighted
* No mention of certificate trust during export/import

==== Recommendation

Add to the "Migrating Registry Applications" section:

[source,asciidoc]
----
=== TLS/HTTPS Configuration

If your Registry deployment uses HTTPS, note these important details:

==== Server-Side Configuration (No Changes Required)

Both Registry 2.x and 3.x use identical Quarkus SSL configuration. You can reuse the same certificates and
configuration:

[source,properties]
----
# These properties are identical for v2 and v3
QUARKUS_HTTP_SSL_PORT=8443
QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_FILE=/path/to/keystore.p12
QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_PASSWORD=your-password
QUARKUS_HTTP_INSECURE_REQUESTS=disabled
----

*Migration Impact:* You can use the same TLS certificates for both v2 and v3 registries during the migration period.

==== Client-Side Configuration (Code Changes Required)

Client applications must update their SSL configuration approach when migrating to v3 clients.

===== v2 Client SSL Configuration

v2 clients use JVM system properties for SSL/TLS configuration:

[source,java]
----
// Set system properties before creating client
System.setProperty("javax.net.ssl.trustStore", "/path/to/truststore.jks");
System.setProperty("javax.net.ssl.trustStorePassword", "password");
System.setProperty("javax.net.ssl.keyStore", "/path/to/keystore.jks");       // for mTLS
System.setProperty("javax.net.ssl.keyStorePassword", "password");             // for mTLS

// Create client (automatically uses system SSL context)
String registryUrl = "https://registry.example.com/apis/registry/v2";
RegistryClient client = RegistryClientFactory.create(registryUrl);
----

===== v3 Client SSL Configuration

v3 clients use the `RegistryClientOptions` API for explicit SSL configuration:

[source,java]
----
// Configure SSL explicitly via RegistryClientOptions
String registryUrl = "https://registry.example.com/apis/registry/v3";

RegistryClientOptions options = RegistryClientOptions.create(registryUrl)
    .trustStoreJks("/path/to/truststore.jks", "password")
    .keyStoreJks("/path/to/keystore.jks", "password");    // for mTLS

RegistryClient client = RegistryClientFactory.create(options);
----

===== Alternative: Trust All Certificates (Testing Only)

For testing environments with self-signed certificates, v3 clients support disabling certificate validation:

[source,java]
----
RegistryClientOptions options = RegistryClientOptions.create(registryUrl)
    .trustAll(true);  // NOT recommended for production
----

*Security Warning:* Never use `trustAll(true)` in production environments.

===== Migration Strategy for Client Applications

When migrating client applications:

1. *Phase 1:* Keep using v2 clients against v3 registry (backward compatible)
   - No code changes required
   - System properties continue to work
2. *Phase 2:* Update dependencies to v3 client libraries
3. *Phase 3:* Update code to use `RegistryClientOptions` API
4. *Phase 4:* Remove system property configuration

This phased approach allows gradual migration without all-or-nothing updates.

==== Export/Import with HTTPS

When exporting and importing over HTTPS, you may need to handle certificate trust:

===== Using curl with Self-Signed Certificates

[source,bash]
----
# Option 1: Disable certificate verification (testing only)
curl -k -X GET "https://registry.example.com/apis/registry/v2/admin/export" \
  -H "Authorization: Bearer $TOKEN" \
  -o registry-export.zip

# Option 2: Specify CA certificate
curl --cacert /path/to/ca-cert.pem \
  -X GET "https://registry.example.com/apis/registry/v2/admin/export" \
  -H "Authorization: Bearer $TOKEN" \
  -o registry-export.zip
----

===== Client Certificate Authentication (mTLS)

If using mutual TLS:

[source,bash]
----
curl --cert /path/to/client-cert.pem \
     --key /path/to/client-key.pem \
     --cacert /path/to/ca-cert.pem \
     -X GET "https://registry.example.com/apis/registry/v2/admin/export" \
     -o registry-export.zip
----

==== Certificate Management Best Practices

During migration:

1. Use the **same certificates** for both v2 and v3 registries (reduces complexity)
2. Ensure certificates include all necessary SAN entries:
   - `registry-v2.example.com`
   - `registry-v3.example.com`
   - `registry.example.com` (load balancer hostname)
3. If using separate certificates, ensure clients trust both CA certificates
4. Plan certificate renewal independently of migration (don't combine these activities)
----

=== Gap 6: Missing Kafka SerDes Application Migration

==== What Scenarios 2 & 4 Demonstrate

These scenarios show complete Kafka producer/consumer application migration:

*Test Flow:*

1. Run v2 producer → v2 registry (before migration)
2. Run v2 consumer → v2 registry (before migration)
3. Migrate registry from v2 to v3
4. Run v2 producer → v3 registry (backward compatibility test)
5. Run v2 consumer → v3 registry (can read v2 producer messages)
6. Run v3 producer → v3 registry (native v3)
7. Run v3 consumer → v3 registry (can read both v2 and v3 messages)

*Key Findings:*

* v2 SerDes libraries work with v3 registry (full backward compatibility)
* v3 SerDes can deserialize messages from v2 SerDes (forward compatibility)
* Configuration changes are minimal (just registry URL)
* Enables gradual migration of applications

==== What the Guide Currently Says

From `migration.adoc` line 135:

[source]
----
. If you build Kafka SerDes integrations, verify that serializers and deserializers still reference the correct
registry URL and consider enabling group- or artifact-level rules introduced in 3.x to enforce compatibility
upstream.
----

*Problems:*

* Only one sentence for a critical use case
* No migration strategy
* No explanation of backward compatibility
* No code examples
* No dependency update guidance

==== Recommendation

Expand this to a full subsection:

[source,asciidoc]
----
=== Migrating Kafka Applications Using Apicurio SerDes

Many Apicurio Registry deployments serve as the schema registry for Kafka-based applications. Migrating these
applications requires careful planning to avoid message consumption failures.

==== Backward Compatibility Guarantee

Registry 3.x provides full backward compatibility for v2 SerDes libraries:

* Existing Kafka applications using v2 Avro, Protobuf, or JSON Schema SerDes continue to work after migrating the
  registry to v3
* No code changes required initially
* Only configuration update needed (registry URL)

This enables a **phased migration** where you migrate the registry first, then gradually update applications.

==== Forward Compatibility

Registry 3.x SerDes can deserialize messages produced by v2 SerDes:

* v3 consumers can read messages from v2 producers
* Enables gradual migration of producers and consumers
* No "big bang" migration required

==== Migration Strategy

Recommended approach for Kafka application migration:

.Phase 1: Migrate Registry Server
1. Export data from v2 registry
2. Deploy v3 registry
3. Import data into v3 registry
4. Switch clients to v3 registry URL
5. *Keep v2 SerDes libraries in applications* (no changes yet)

.Phase 2: Update Application Configuration
Update Kafka application configuration to point to v3 registry:

*Before (v2 registry):*
[source,properties]
----
apicurio.registry.url=http://registry-v2.example.com/apis/registry/v2
apicurio.registry.auto-register=true
----

*After (v3 registry, still using v2 SerDes):*
[source,properties]
----
# Note: URL points to v3 registry, but still using /v2 API path
apicurio.registry.url=http://registry-v3.example.com/apis/registry/v2
apicurio.registry.auto-register=true
----

.Phase 3: Validate v2 SerDes on v3 Registry
1. Deploy updated configuration to test environment
2. Run producer applications (should auto-register schemas)
3. Run consumer applications (should deserialize successfully)
4. Monitor for errors
5. Deploy to production

.Phase 4: Migrate to v3 SerDes (Gradual)
For each application:

1. Update Maven/Gradle dependencies
2. Update configuration to use v3 API path
3. Test in non-production environment
4. Deploy to production

*Note:* You can migrate applications one at a time. v2 and v3 SerDes can coexist.

==== Dependency Updates

===== Maven (Java)

*v2 SerDes dependencies:*
[source,xml]
----
<dependency>
    <groupId>io.apicurio</groupId>
    <artifactId>apicurio-registry-serdes-avro-serde</artifactId>
    <version>2.6.13.Final</version>
</dependency>
----

*v3 SerDes dependencies:*
[source,xml]
----
<dependency>
    <groupId>io.apicurio</groupId>
    <artifactId>apicurio-registry-serdes-avro-serde</artifactId>
    <version>3.1.2</version>
</dependency>
----

===== Configuration Changes

*v2 SerDes configuration (still works with v3 registry):*
[source,java]
----
Properties props = new Properties();
props.put(SerdeConfig.REGISTRY_URL, "http://registry.example.com/apis/registry/v2");
props.put(SerdeConfig.AUTO_REGISTER_ARTIFACT, true);

KafkaAvroSerializer serializer = new KafkaAvroSerializer();
serializer.configure(props, false);
----

*v3 SerDes configuration:*
[source,java]
----
Properties props = new Properties();
props.put(SerdeConfig.REGISTRY_URL, "http://registry.example.com/apis/registry/v3");
props.put(SerdeConfig.AUTO_REGISTER_ARTIFACT, true);

KafkaAvroSerializer serializer = new KafkaAvroSerializer();
serializer.configure(props, false);
----

==== Authentication for SerDes

If using OAuth2 authentication, update SerDes configuration:

*v2 SerDes with OAuth2:*
[source,properties]
----
apicurio.registry.url=https://registry.example.com/apis/registry/v2
apicurio.auth.service.url=https://keycloak.example.com/realms/registry
apicurio.auth.client.id=kafka-client
apicurio.auth.client.secret=secret
----

*v3 SerDes with OAuth2:*
[source,properties]
----
apicurio.registry.url=https://registry.example.com/apis/registry/v3
apicurio.auth.service.url=https://keycloak.example.com/realms/registry
apicurio.auth.client.id=kafka-client
apicurio.auth.client.secret=secret
----

*Note:* Authentication configuration is largely the same between v2 and v3 SerDes.

==== TLS/HTTPS for SerDes

If registry uses HTTPS:

*v2 SerDes (system properties):*
[source,java]
----
System.setProperty("javax.net.ssl.trustStore", "/path/to/truststore.jks");
System.setProperty("javax.net.ssl.trustStorePassword", "password");
----

*v3 SerDes (explicit configuration):*
[source,properties]
----
apicurio.registry.request.ssl.truststore.location=/path/to/truststore.jks
apicurio.registry.request.ssl.truststore.password=password
apicurio.registry.request.ssl.truststore.type=JKS
----

==== Testing Kafka Application Migration

Create a test plan:

[cols="1,2,1",options="header"]
|===
| Test Scenario | Description | Expected Result

| v2 Producer → v3 Registry
| Existing v2 producer publishes to Kafka
| Schema auto-registers in v3, messages serialize correctly

| v2 Consumer → v3 Registry
| Existing v2 consumer reads messages
| Deserializes successfully using schemas from v3

| v3 Producer → v3 Registry
| New v3 producer publishes to Kafka
| Schema auto-registers, messages serialize correctly

| v3 Consumer reads v2 messages
| v3 consumer reads old messages from v2 producer
| Deserializes successfully (forward compatibility)

| v3 Consumer reads v3 messages
| v3 consumer reads new messages from v3 producer
| Deserializes successfully

| Mixed environment
| v2 and v3 apps coexist
| All producers and consumers work correctly
|===

==== Rollback Considerations

If issues arise after migrating SerDes:

1. *Registry level:* Switch load balancer back to v2 registry
2. *Application level:* Revert to previous version with v2 SerDes
3. v2 SerDes applications are unaware of v3-specific features, providing safe fallback

Recommendation: Migrate applications one at a time to limit blast radius.
----

=== Gap 7: Missing Complete Configuration Property Mappings

==== Issues Identified

The current configuration tables are incomplete. Comparing against the scenarios:

===== Missing KafkaSQL Properties

Current table (lines 206-219) shows:

[cols="1,1",options="header"]
|===
| Registry 2.x property | Registry 3.x property
| `registry.events.kafka.topic` | `apicurio.events.kafka.topic`
| `registry.kafkasql.bootstrap.servers` | `apicurio.kafkasql.bootstrap.servers`
| `registry.kafkasql.topic.auto-create` | `apicurio.kafkasql.topic.auto-create`
|===

*Missing properties found in scenarios:*

* `KAFKA_BOOTSTRAP_SERVERS` (v2) → `APICURIO_KAFKASQL_BOOTSTRAP_SERVERS` (v3)
* `REGISTRY_KAFKASQL_TOPIC` (v2) → `APICURIO_KAFKASQL_TOPIC` (v3)
* `REGISTRY_KAFKASQL_CONSUMER_GROUP_ID` (v2) → (removed in v3)
* Missing: `APICURIO_STORAGE_KIND=kafkasql` (required in v3)

===== Missing Database Properties

Current table (lines 254-270) shows:

[cols="1,1",options="header"]
|===
| Registry 2.x property | Registry 3.x property
| `quarkus.datasource.jdbc.url` | `apicurio.datasource.url`
| `quarkus.datasource.username` | `apicurio.datasource.username`
|===

*Issues:*

* Scenario 4 v2 uses: `REGISTRY_DATASOURCE_URL` (not `quarkus.datasource.jdbc.url`)
* Missing: `QUARKUS_DATASOURCE_DB_KIND` (used in v2)
* Missing: `APICURIO_STORAGE_KIND=sql` (required in v3)
* Missing: `APICURIO_STORAGE_SQL_KIND=postgresql` (required in v3)

===== Missing Authentication Properties

Current table (lines 169-188) is incomplete:

*Missing from v2:*

* `AUTH_ENABLED=true`
* `KEYCLOAK_URL`
* `KEYCLOAK_REALM`
* `KEYCLOAK_API_CLIENT_ID`
* `ROLE_BASED_AUTHZ_ENABLED`

*Missing from v3:*

* `QUARKUS_OIDC_TENANT_ENABLED`
* `QUARKUS_OIDC_AUTH_SERVER_URL`
* `apicurio.auth.role-based-authorization`

==== Recommendation

Create comprehensive, scenario-validated configuration tables:

[source,asciidoc]
----
=== Complete Configuration Property Mapping

This section provides complete property mappings validated against production-like deployments.

==== Database (SQL) Storage Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| `REGISTRY_DATASOURCE_URL`
| `APICURIO_DATASOURCE_URL`
| JDBC connection URL

| `REGISTRY_DATASOURCE_USERNAME`
| `APICURIO_DATASOURCE_USERNAME`
| Database username

| `REGISTRY_DATASOURCE_PASSWORD`
| `APICURIO_DATASOURCE_PASSWORD`
| Database password

| `QUARKUS_DATASOURCE_DB_KIND`
| `APICURIO_STORAGE_SQL_KIND`
| Database type (postgresql, mysql, etc.)

| (implicit: sql)
| `APICURIO_STORAGE_KIND=sql`
| **Required in v3** to select SQL storage

| `REGISTRY_SQL_INIT`
| `APICURIO_SQL_INIT`
| Auto-initialize database schema

| (implicit)
| `APICURIO_STORAGE_KIND=sql`
| Storage type selection (new in v3)
|===

*Example v2 configuration:*
[source,properties]
----
REGISTRY_DATASOURCE_URL=jdbc:postgresql://db:5432/registry
REGISTRY_DATASOURCE_USERNAME=apicurio
REGISTRY_DATASOURCE_PASSWORD=password123
QUARKUS_DATASOURCE_DB_KIND=postgresql
----

*Example v3 configuration:*
[source,properties]
----
APICURIO_STORAGE_KIND=sql
APICURIO_STORAGE_SQL_KIND=postgresql
APICURIO_DATASOURCE_URL=jdbc:postgresql://db:5432/registry
APICURIO_DATASOURCE_USERNAME=apicurio
APICURIO_DATASOURCE_PASSWORD=password123
----

==== KafkaSQL Storage Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| (implicit: kafkasql)
| `APICURIO_STORAGE_KIND=kafkasql`
| **Required in v3** to select KafkaSQL storage

| `KAFKA_BOOTSTRAP_SERVERS`
| `APICURIO_KAFKASQL_BOOTSTRAP_SERVERS`
| Kafka broker addresses

| `REGISTRY_KAFKASQL_TOPIC`
| `APICURIO_KAFKASQL_TOPIC`
| Topic name for registry journal

| `REGISTRY_KAFKASQL_TOPIC_AUTO_CREATE`
| `APICURIO_KAFKASQL_TOPIC_AUTO_CREATE`
| Auto-create topic if missing

| `REGISTRY_KAFKASQL_CONSUMER_GROUP_ID`
| (removed)
| Auto-generated in v3

| `REGISTRY_KAFKASQL_TOPIC_PARTITION_COUNT`
| `APICURIO_KAFKASQL_TOPIC_PARTITIONS`
| Partition count for topic

| `REGISTRY_KAFKASQL_TOPIC_REPLICATION_FACTOR`
| `APICURIO_KAFKASQL_TOPIC_REPLICATION_FACTOR`
| Replication factor for topic
|===

*Example v2 configuration:*
[source,properties]
----
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
REGISTRY_KAFKASQL_TOPIC=kafkasql-journal
REGISTRY_KAFKASQL_TOPIC_AUTO_CREATE=true
REGISTRY_KAFKASQL_CONSUMER_GROUP_ID=registry-consumer
----

*Example v3 configuration:*
[source,properties]
----
APICURIO_STORAGE_KIND=kafkasql
APICURIO_KAFKASQL_BOOTSTRAP_SERVERS=kafka:9092
APICURIO_KAFKASQL_TOPIC=kafkasql-journal
APICURIO_KAFKASQL_TOPIC_AUTO_CREATE=true
----

==== OAuth2/OIDC Authentication Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| `AUTH_ENABLED`
| `QUARKUS_OIDC_TENANT_ENABLED`
| Enable OAuth2 authentication

| `KEYCLOAK_URL`
| `QUARKUS_OIDC_AUTH_SERVER_URL`
| Note: v3 requires full URL including realm path

| `KEYCLOAK_REALM`
| (included in AUTH_SERVER_URL)
| Realm is part of the URL in v3

| `KEYCLOAK_API_CLIENT_ID`
| `QUARKUS_OIDC_CLIENT_ID`
| OAuth2 client ID

| `KEYCLOAK_UI_CLIENT_ID`
| (UI-specific config)
| UI configuration separate from API

| `REGISTRY_AUTH_ROLES_ADMIN`
| `apicurio.auth.roles.admin`
| Admin role name

| `REGISTRY_AUTH_ROLES_DEVELOPER`
| `apicurio.auth.roles.developer`
| Developer role name

| `REGISTRY_AUTH_ROLES_READONLY`
| `apicurio.auth.roles.readonly`
| Read-only role name

| `ROLE_BASED_AUTHZ_ENABLED`
| `apicurio.auth.role-based-authorization`
| Enable role-based access control

| `REGISTRY_AUTH_ROLE_SOURCE`
| `apicurio.auth.role-source`
| Role source (token, application)

| `REGISTRY_AUTH_ANONYMOUS_READ_ACCESS_ENABLED`
| `apicurio.auth.anonymous-read-access.enabled`
| Allow unauthenticated reads

| `QUARKUS_OIDC_TLS_VERIFICATION`
| `QUARKUS_OIDC_TLS_VERIFICATION`
| TLS verification for OIDC (same in v2/v3)
|===

*Example v2 configuration:*
[source,properties]
----
AUTH_ENABLED=true
KEYCLOAK_URL=https://keycloak.example.com:8443
KEYCLOAK_REALM=registry
KEYCLOAK_API_CLIENT_ID=registry-api
ROLE_BASED_AUTHZ_ENABLED=true
REGISTRY_AUTH_ROLES_ADMIN=sr-admin
REGISTRY_AUTH_ROLES_DEVELOPER=sr-developer
REGISTRY_AUTH_ROLES_READONLY=sr-readonly
----

*Example v3 configuration:*
[source,properties]
----
QUARKUS_OIDC_TENANT_ENABLED=true
QUARKUS_OIDC_AUTH_SERVER_URL=https://keycloak.example.com:8443/realms/registry
QUARKUS_OIDC_CLIENT_ID=registry-api
apicurio.auth.role-based-authorization=true
apicurio.auth.roles.admin=sr-admin
apicurio.auth.roles.developer=sr-developer
apicurio.auth.roles.readonly=sr-readonly
----

*Critical difference:* v3 requires the full realm path in `QUARKUS_OIDC_AUTH_SERVER_URL`:
----
v2: KEYCLOAK_URL=https://keycloak:8443 + KEYCLOAK_REALM=registry
v3: QUARKUS_OIDC_AUTH_SERVER_URL=https://keycloak:8443/realms/registry
----

==== TLS/HTTPS Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| `QUARKUS_HTTP_SSL_PORT`
| `QUARKUS_HTTP_SSL_PORT`
| **No change** - same in v2 and v3

| `QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_FILE`
| `QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_FILE`
| **No change** - same in v2 and v3

| `QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_PASSWORD`
| `QUARKUS_HTTP_SSL_CERTIFICATE_KEY_STORE_PASSWORD`
| **No change** - same in v2 and v3

| `QUARKUS_HTTP_INSECURE_REQUESTS`
| `QUARKUS_HTTP_INSECURE_REQUESTS`
| **No change** - same in v2 and v3
|===

*Good news:* TLS configuration is identical between v2 and v3. You can reuse certificates and configuration.

==== API and UI Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| `REGISTRY_UI_FEATURES_READONLY`
| `apicurio.ui.features.read-only.enabled`
| Enable read-only UI mode

| `REGISTRY_UI_CONTEXT_PATH`
| `apicurio.ui.contextPath`
| UI context path (usually `/ui`)

| `REGISTRY_API_ERRORS_INCLUDE_STACK_IN_RESPONSE`
| `apicurio.api.errors.include-stack-in-response`
| Include stack traces in errors

| `CORS_ALLOWED_ORIGINS`
| `QUARKUS_HTTP_CORS_ORIGINS`
| CORS allowed origins

| `REGISTRY_REST_ARTIFACT_DELETION_ENABLED`
| `apicurio.rest.deletion.artifact.enabled`
| Enable artifact deletion via API

| (not available)
| `apicurio.rest.deletion.group.enabled`
| Enable group deletion (new in v3)

| (not available)
| `apicurio.rest.deletion.artifact-version.enabled`
| Enable version deletion (new in v3)
|===

==== Logging Configuration

[cols="2,2,2",options="header"]
|===
| Registry 2.x Property | Registry 3.x Property | Notes

| `LOG_LEVEL`
| `QUARKUS_LOG_LEVEL`
| Root log level

| `REGISTRY_LOG_LEVEL`
| (use package-specific logging)
| Use `QUARKUS_LOG_CATEGORY_IO_APICURIO_LEVEL` in v3

| `QUARKUS_LOG_LEVEL`
| `QUARKUS_LOG_LEVEL`
| **No change**
|===
----

=== Gap 8: Missing Rollback Strategy

==== What the Scenarios Enable

The scenarios demonstrate a migration pattern that enables safe rollback:

* v2 and v3 registries run in parallel
* v2 database/Kafka remains unchanged during export (read-only operation)
* nginx/load balancer can switch back to v2 if issues arise
* Separate storage means no risk of data corruption

==== What the Guide Currently Says

Nothing about rollback procedures or recovery strategies.

==== Recommendation

Add a new section:

[source,asciidoc]
----
== Rollback Procedure

The migration approach using a reverse proxy enables safe rollback if issues arise after switching to Registry 3.x.

=== When to Rollback

Consider rolling back to v2 if you encounter:

* High error rates in client applications after switching to v3
* Data inconsistencies or missing artifacts in v3
* Performance degradation
* Unexpected behavior in v3-specific features
* Critical bugs in the v3 release

=== How to Rollback

The rollback procedure is straightforward if you followed the recommended migration approach:

==== Immediate Rollback (within minutes)

If issues are detected immediately after switching:

[source,bash]
----
# 1. Switch load balancer back to v2 registry
# (update nginx configuration to point to v2)
docker compose -f docker-compose-nginx-v2.yml up -d

# 2. Verify traffic is flowing to v2
curl http://load-balancer:8080/apis/registry/v2/system/info | jq '.version'
# Should show 2.6.x version

# 3. Monitor application logs for recovery
----

*Recovery time:* 30-60 seconds (time to reload load balancer)

==== Delayed Rollback (within hours/days)

If issues are discovered hours or days after migration:

*Consideration:* New data may have been created in v3 registry after the switch.

.Options:

*Option 1: Accept data loss and rollback to v2*
1. Switch load balancer back to v2
2. Any artifacts created in v3 since migration will not be available
3. Manually recreate critical artifacts if needed

*Option 2: Export from v3 and re-import to v2*
1. Export data from v3 registry
2. Import into v2 registry (if v2 accepts v3 exports - check compatibility)
3. Switch load balancer back to v2

*Option 3: Fix v3 issues and stay on v3*
1. Investigate and resolve v3 issues
2. Keep v3 as the active registry
3. Most common approach

==== Preventing Need for Rollback

Follow these practices to minimize rollback risk:

[cols="1,3",options="header"]
|===
| Practice | Description

| Thorough testing
| Test migration in staging environment that mirrors production

| Gradual rollout
| Migrate non-critical registries first, learn from issues

| Validation
| Run complete validation suite before switching production traffic

| Monitoring
| Set up monitoring and alerting before migration

| Off-hours migration
| Perform migration during low-traffic periods

| Phased client migration
| Keep v2 clients initially, migrate to v3 clients gradually

| Keep v2 running
| Maintain v2 for 1-7 days after migration for quick rollback
|===

==== Cleanup After Successful Migration

After 1-7 days of successful operation on v3:

[source,bash]
----
# 1. Verify v3 is stable and no rollback needed
# 2. Document any issues encountered and resolutions

# 3. Shut down v2 registry
docker compose -f docker-compose-v2.yml down

# 4. Clean up v2 database (optional - consider backup first)
# For PostgreSQL:
# DROP DATABASE registry_v2;

# 5. Clean up v2 KafkaSQL topic (if applicable)
# kafka-topics.sh --bootstrap-server kafka:9092 --delete --topic kafkasql-journal-v2

# 6. Update documentation to reflect v3 as production registry
----

=== Data Loss Scenarios

Understand the data loss implications:

[cols="2,2,2",options="header"]
|===
| Rollback Timing | Data Status | Risk

| Before switching to v3
| v2 unchanged, v3 has import
| Zero data loss (nothing committed to v3)

| Immediately after switch (< 1 hour)
| Minimal new data in v3
| Low risk (manually recreate if needed)

| Days after switch
| Significant new data in v3
| High risk (export from v3 needed)
|===

*Recommendation:* Plan for 24-hour observation period after migration. During this time, monitor closely and be
prepared for quick rollback if needed.
----

=== Gap 9: Missing Step-by-Step Integrated Workflow

==== What the Scenarios Demonstrate

All scenarios follow a consistent, proven workflow with clear phases and validation gates.

==== What the Guide Currently Says

The guide has three separate sections (data migration, client migration, config migration) but no integrated
workflow showing how they fit together.

==== Recommendation

Add a new section early in the document:

[source,asciidoc]
----
== Complete Migration Workflow

This section provides a step-by-step workflow integrating all aspects of the migration. Each step includes
validation checkpoints to ensure a successful migration.

=== Overview

[literal]
....
┌────────────────────────────────────────────────────────────────┐
│ PHASE 1: PREPARATION (No Downtime)                             │
├────────────────────────────────────────────────────────────────┤
│ 1. Review migration guide and plan downtime window             │
│ 2. Set up staging environment for testing                      │
│ 3. Test migration in staging                                   │
│ 4. Deploy load balancer in front of v2 (if not already)        │
│ 5. Prepare v3 infrastructure (database/Kafka)                  │
│ ✓ Checkpoint: v2 traffic flowing through load balancer         │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 2: PRE-MIGRATION VALIDATION (No Downtime)                │
├────────────────────────────────────────────────────────────────┤
│ 6. Record baseline metrics from v2                             │
│ 7. Capture artifact counts, rules, sample data                 │
│ 8. Save validation report for comparison                       │
│ ✓ Checkpoint: Baseline documented                              │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 3: DATA MIGRATION (No Downtime)                          │
├────────────────────────────────────────────────────────────────┤
│ 9. Export data from v2 registry (read-only operation)          │
│ 10. Deploy Registry 3.x (not receiving traffic yet)            │
│ 11. Import data into v3 registry                               │
│ 12. Validate import (compare artifact counts)                  │
│ ✓ Checkpoint: v3 has all data, v2 still serving traffic        │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 4: TRAFFIC SWITCH (Downtime: ~30 seconds)                │
├────────────────────────────────────────────────────────────────┤
│ 13. Update load balancer to route to v3                        │
│ 14. Reload load balancer configuration                         │
│ 15. Verify traffic flowing to v3                               │
│ ✓ Checkpoint: All traffic on v3                                │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 5: POST-MIGRATION VALIDATION (No Downtime)               │
├────────────────────────────────────────────────────────────────┤
│ 16. Test v2 clients against v3 (backward compatibility)        │
│ 17. Test v3 native functionality                               │
│ 18. Verify Kafka SerDes applications (if applicable)           │
│ 19. Run smoke tests on critical applications                   │
│ 20. Monitor error rates and performance                        │
│ ✓ Checkpoint: All validations passed                           │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 6: STABILIZATION (No Downtime)                           │
├────────────────────────────────────────────────────────────────┤
│ 21. Keep v2 running for rollback capability (1-7 days)         │
│ 22. Monitor v3 in production                                   │
│ 23. Begin gradual client application migration                 │
│ ✓ Checkpoint: v3 stable, no rollback needed                    │
└────────────────────────────────────────────────────────────────┘

┌────────────────────────────────────────────────────────────────┐
│ PHASE 7: CLEANUP (After Validation Period)                     │
├────────────────────────────────────────────────────────────────┤
│ 24. Decommission v2 registry                                   │
│ 25. Clean up v2 database/Kafka topics                          │
│ 26. Update documentation                                       │
│ ✓ Checkpoint: Migration complete                               │
└────────────────────────────────────────────────────────────────┘
....

=== Detailed Steps

==== Phase 1: Preparation

===== Step 1: Review and Plan

* Read complete migration guide
* Review configuration changes needed
* Plan downtime window (typically off-hours)
* Identify stakeholders and communication plan

===== Step 2: Set Up Staging Environment

Create a staging environment that mirrors production:

* Same storage type (SQL/KafkaSQL)
* Same authentication method (OAuth2/OIDC)
* Same TLS configuration
* Representative test data

===== Step 3: Test Migration in Staging

Execute complete migration workflow in staging:

* Export from staging v2
* Deploy staging v3
* Import into staging v3
* Test client applications
* Measure downtime during switch
* Document any issues

===== Step 4: Deploy Load Balancer

If not already using a load balancer:

[source,bash]
----
# Example nginx deployment
docker run -d --name nginx \
  -v ./nginx.conf:/etc/nginx/nginx.conf:ro \
  -p 8080:8080 \
  nginx:alpine
----

Update clients to connect through load balancer instead of directly to registry.

===== Step 5: Prepare v3 Infrastructure

* Deploy database for v3 (separate from v2)
* For KafkaSQL: same Kafka cluster, different topic
* Prepare TLS certificates (can reuse v2 certificates)
* Configure authentication (OAuth2 provider)

*Checkpoint:* Verify v2 traffic flowing correctly through load balancer.

==== Phase 2: Pre-Migration Validation

===== Step 6-8: Capture Baseline

Run validation scripts to capture v2 state:

[source,bash]
----
#!/bin/bash
# capture-baseline.sh

REGISTRY_URL="http://load-balancer:8080/apis/registry/v2"
OUTPUT_DIR="./migration-baseline"
mkdir -p "$OUTPUT_DIR"

# Artifact count
curl -s "$REGISTRY_URL/search/artifacts" | jq '.count' > "$OUTPUT_DIR/artifact-count.txt"

# Artifact list
curl -s "$REGISTRY_URL/search/artifacts?limit=1000" \
  | jq '.artifacts[] | {id, type, name}' > "$OUTPUT_DIR/artifacts.json"

# Global rules
curl -s "$REGISTRY_URL/admin/rules" > "$OUTPUT_DIR/global-rules.json"

# Sample artifacts for detailed comparison
for artifactId in $(jq -r '.[0:10].id' "$OUTPUT_DIR/artifacts.json"); do
    echo "Capturing: $artifactId"
    curl -s "$REGISTRY_URL/artifacts/$artifactId" > "$OUTPUT_DIR/artifact-$artifactId.json"
done

echo "Baseline captured in $OUTPUT_DIR"
----

*Checkpoint:* Baseline files saved and reviewed.

==== Phase 3: Data Migration

===== Step 9: Enable Read-Only Mode (Critical for Data Consistency)

Before exporting, configure the load balancer to block write operations. This ensures no data changes occur during
export, guaranteeing 100% data consistency.

*Create read-only nginx configuration:*

[source,nginx]
----
# File: nginx/conf.d/registry-v2-readonly.conf
upstream registry {
    server registry-v2:8080;
}

server {
    listen 8080;

    location / {
        # Block write operations during migration
        if ($request_method !~ ^(GET|HEAD|OPTIONS)$) {
            return 405 "Registry is temporarily in read-only mode for migration. Writes will resume shortly.";
        }

        proxy_pass http://registry;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # Allow health checks to pass through
    location /health {
        proxy_pass http://registry;
    }

    # Allow admin export endpoint (direct access, not through load balancer)
}
----

*Apply read-only configuration:*

[source,bash]
----
# Switch nginx to read-only mode
docker exec nginx cp /configs/registry-v2-readonly.conf /etc/nginx/conf.d/default.conf
docker exec nginx nginx -s reload

# Verify read-only mode is active
echo "Testing read-only mode..."

# This should succeed (GET request)
curl -s http://load-balancer:8080/apis/registry/v2/search/artifacts | jq '.count'

# This should fail with 405 (POST request)
curl -X POST http://load-balancer:8080/apis/registry/v2/groups/default/artifacts \
  -H "Content-Type: application/json" \
  -d '{"type":"AVRO","name":"test"}' \
  -w "\nHTTP Status: %{http_code}\n"

# Expected output: HTTP Status: 405
----

*Notify stakeholders:*

[source,bash]
----
# Send notification to operations team
echo "$(date): Registry switched to read-only mode for migration" >> migration-log.txt

# Expected impact:
# - Read operations (schema lookups): continue normally
# - Write operations (new schemas, updates): blocked with HTTP 405
# - Kafka producers with auto-register: will fail to register new schemas
----

*Checkpoint:* Read-only mode verified, write operations blocked, read operations working.

===== Step 10: Export from v2

Now export data while the registry is in read-only mode:

[source,bash]
----
# For authenticated deployments, get token first (see authentication section)
TOKEN=$(curl -s -X POST "https://keycloak/realms/registry/protocol/openid-connect/token" \
  -d "grant_type=client_credentials" \
  -d "client_id=admin-client" \
  -d "client_secret=$CLIENT_SECRET" \
  | jq -r '.access_token')

# Export directly from registry (bypass nginx to avoid read-only restriction on admin endpoint)
# Note: Access v2 registry directly, not through load balancer
curl -X GET "http://registry-v2:8080/apis/registry/v2/admin/export" \
  -H "Authorization: Bearer $TOKEN" \
  -o registry-export.zip

# Verify export
ls -lh registry-export.zip
unzip -l registry-export.zip

# Log export completion
echo "$(date): Export completed. File size: $(ls -lh registry-export.zip | awk '{print $5}')" >> migration-log.txt
----

*Important:* Keep v2 in read-only mode throughout the remaining migration steps until v3 is validated and traffic
is switched.

*Checkpoint:* Export complete, data snapshot captured with 100% consistency guarantee.

===== Step 11: Deploy Registry v3

[source,bash]
----
# Example Docker Compose deployment
docker compose -f docker-compose-v3.yml up -d

# Wait for health check
timeout 120 bash -c 'until curl -f http://registry-v3:8080/health/live; do sleep 2; done'
----

===== Step 12: Import into v3

[source,bash]
----
curl -X POST "http://registry-v3:8080/apis/registry/v3/admin/import" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/zip" \
  --data-binary @registry-export.zip

# Check response (should be 200 or 204)
echo "$(date): Import completed" >> migration-log.txt
----

===== Step 13: Validate Import

[source,bash]
----
# Compare artifact counts
V2_COUNT=$(cat migration-baseline/artifact-count.txt)
V3_COUNT=$(curl -s "http://registry-v3:8080/apis/registry/v3/search/artifacts" | jq '.count')

if [ "$V2_COUNT" -eq "$V3_COUNT" ]; then
    echo "✓ Artifact counts match: $V3_COUNT"
else
    echo "✗ MISMATCH: v2=$V2_COUNT, v3=$V3_COUNT"
    exit 1
fi
----

*Checkpoint:* v3 has all data, artifact count matches, ready to switch traffic.

==== Phase 4: Traffic Switch (Resumes Write Operations)

===== Step 14-15: Update Load Balancer to v3 (Read/Write Enabled)

Now switch nginx to route to v3, which will automatically enable write operations:

[source,bash]
----
# Create v3 configuration with read/write enabled
# File: nginx/conf.d/registry-v3-readwrite.conf
cat > nginx/conf.d/registry-v3-readwrite.conf << 'EOF'
upstream registry {
    server registry-v3:8080;
}

server {
    listen 8080;

    location / {
        # All methods allowed (read/write enabled)
        proxy_pass http://registry;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /health {
        proxy_pass http://registry;
    }
}
EOF

# Switch nginx to v3 configuration
docker exec nginx cp /configs/registry-v3-readwrite.conf /etc/nginx/conf.d/default.conf
docker exec nginx nginx -s reload

# Log the switch
echo "$(date): Traffic switched to v3. Write operations RESUMED." >> migration-log.txt
----

===== Step 16: Verify Traffic and Write Operations

[source,bash]
----
# Check version through load balancer
curl -s "http://load-balancer:8080/apis/registry/v3/system/info" | jq '.version'
# Should show 3.x version

# Verify write operations now work (should succeed with HTTP 201)
curl -X POST http://load-balancer:8080/apis/registry/v3/groups/default/artifacts \
  -H "Content-Type: application/json" \
  -H "X-Registry-ArtifactId: test-post-migration" \
  -H "X-Registry-ArtifactType: JSON" \
  -d '{"type":"object","properties":{"test":{"type":"string"}}}' \
  -w "\nHTTP Status: %{http_code}\n"

# Expected: HTTP Status: 201 (write operations resumed)

# Monitor logs
docker logs -f registry-v3 &

echo "$(date): Write operations verified on v3" >> migration-log.txt
----

*Checkpoint:* All traffic routed to v3, write operations working, no errors in logs.

==== Phase 5: Post-Migration Validation

===== Step 17: Test v2 Backward Compatibility

[source,bash]
----
# Test v2 API endpoints on v3 registry
curl -s "http://load-balancer:8080/apis/registry/v2/search/artifacts?limit=10" | jq .

# Run v2 client application tests
java -jar my-v2-client-app.jar --registry-url http://load-balancer:8080/apis/registry/v2
----

===== Step 17: Test v3 Native Features

[source,bash]
----
# Test v3 search endpoints
curl -s "http://load-balancer:8080/apis/registry/v3/search/groups" | jq .
curl -s "http://load-balancer:8080/apis/registry/v3/search/versions?limit=10" | jq .

# Test branch functionality
curl -s "http://load-balancer:8080/apis/registry/v3/groups/default/artifacts/example/branches" | jq .
----

===== Step 18: Verify Kafka Applications

[source,bash]
----
# Run Kafka producer (should auto-register schemas)
java -jar kafka-producer-app.jar

# Run Kafka consumer (should deserialize successfully)
java -jar kafka-consumer-app.jar

# Check for errors in application logs
----

===== Step 19-20: Smoke Tests and Monitoring

* Run production smoke tests
* Monitor error rates in application logs
* Check performance metrics (latency, throughput)
* Verify no increase in 4xx/5xx errors

*Checkpoint:* All validations passed, production traffic stable.

==== Phase 6: Stabilization

===== Step 21-23: Monitor and Migrate Clients

* Keep v2 running but not serving traffic (rollback capability)
* Monitor v3 for 24-48 hours minimum
* Begin migrating client applications to v3 native clients
* Update Kafka SerDes from v2 to v3 gradually

*Checkpoint:* v3 stable for 1-7 days, ready to decommission v2.

==== Phase 7: Cleanup

===== Step 24-26: Decommission v2

[source,bash]
----
# Shut down v2 registry
docker compose -f docker-compose-v2.yml down

# Optional: Back up v2 database before deletion
pg_dump -U apicurio registry_v2 > registry-v2-backup-$(date +%Y%m%d).sql

# Delete v2 database (be absolutely certain first!)
# psql -U postgres -c "DROP DATABASE registry_v2;"

# Delete v2 KafkaSQL topic (if applicable)
# kafka-topics.sh --bootstrap-server kafka:9092 --delete --topic kafkasql-journal-v2

# Update documentation
echo "Registry migrated to v3.x on $(date)" >> migration-log.txt
----

*Checkpoint:* Migration complete, v2 decommissioned.

=== Time Estimates

Typical timing for each phase (for medium-sized registry with ~1000 artifacts):

[cols="1,2,1",options="header"]
|===
| Phase | Activities | Duration

| 1: Preparation
| Staging tests, infrastructure setup
| 1-2 days

| 2: Pre-Migration Validation
| Baseline capture, review
| 30 minutes

| 3: Data Migration
| Export, deploy v3, import
| 1-2 hours

| 4: Traffic Switch
| Update load balancer
| 30 seconds

| 5: Post-Migration Validation
| Testing, smoke tests
| 2-4 hours

| 6: Stabilization
| Monitoring, client migration
| 1-7 days

| 7: Cleanup
| Decommission v2
| 1 hour
|===

*Total elapsed time:* 2-3 days preparation + 4-6 hours migration + 1-7 days observation

*Actual downtime:* 30-60 seconds (during load balancer switch)
----

=== Gap 10: Missing Troubleshooting Section

==== Recommendation

Add a troubleshooting section based on lessons from the scenarios:

[source,asciidoc]
----
== Troubleshooting

Common issues encountered during migration and their resolutions.

=== Export/Import Issues

==== Problem: Export endpoint returns 401 Unauthorized

*Cause:* Missing or invalid authentication token.

*Solution:*
[source,bash]
----
# Obtain valid access token from OAuth2 provider
TOKEN=$(curl -X POST "https://keycloak/realms/registry/protocol/openid-connect/token" \
  -d "grant_type=client_credentials" \
  -d "client_id=admin-client" \
  -d "client_secret=secret" \
  | jq -r '.access_token')

# Use token in export request
curl -H "Authorization: Bearer $TOKEN" \
  "https://registry-v2/apis/registry/v2/admin/export" -o export.zip
----

==== Problem: Import fails with "Invalid ZIP file"

*Cause:* Export file is corrupted or not a valid ZIP.

*Solution:*
[source,bash]
----
# Verify export file
unzip -t registry-export.zip

# Check file size (should be > 1KB)
ls -lh registry-export.zip

# Re-export if needed
----

==== Problem: Artifact count mismatch after import

*Cause:* Import partially failed or export was incomplete.

*Solution:*

1. Check import logs for errors
2. Drop v3 database and re-import:
[source,sql]
----
DROP SCHEMA public CASCADE;
CREATE SCHEMA public;
----
3. Re-run import with verbose logging

=== Authentication Issues

==== Problem: v3 registry returns 401 for all requests

*Cause:* OAuth2 configuration incorrect.

*Solution:*

Check these configurations:
[source,bash]
----
# v3 requires full realm path in AUTH_SERVER_URL
QUARKUS_OIDC_AUTH_SERVER_URL=https://keycloak:8443/realms/registry  # NOT just https://keycloak:8443

# Verify Keycloak is accessible from v3 container
docker exec registry-v3 curl -k https://keycloak:8443/realms/registry/.well-known/openid-configuration
----

==== Problem: "Invalid token" errors

*Cause:* Token expired or wrong client ID.

*Solution:*

Verify client configuration matches between Keycloak and Registry:
[source,bash]
----
# Check token validity
echo $TOKEN | cut -d. -f2 | base64 -d | jq .

# Verify client ID matches
# In Keycloak: registry-api
# In Registry: QUARKUS_OIDC_CLIENT_ID=registry-api
----

=== Configuration Issues

==== Problem: v3 fails to start with "Storage not configured"

*Cause:* Missing `APICURIO_STORAGE_KIND` property.

*Solution:*
[source,properties]
----
# For SQL storage
APICURIO_STORAGE_KIND=sql
APICURIO_STORAGE_SQL_KIND=postgresql

# For KafkaSQL storage
APICURIO_STORAGE_KIND=kafkasql
----

==== Problem: KafkaSQL v3 shows no data after import

*Cause:* v3 reading from wrong Kafka topic.

*Solution:*

Verify topic configuration:
[source,bash]
----
# Check v3 is using correct topic
docker logs registry-v3 | grep "kafkasql.topic"

# List Kafka topics to confirm
kafka-topics.sh --bootstrap-server kafka:9092 --list | grep kafkasql

# Ensure v3 uses different topic than v2
----

=== Client Application Issues

==== Problem: v2 client fails to connect to v3 registry with SSL error

*Cause:* Client doesn't trust v3's TLS certificate.

*Solution:*

For v2 clients, set system properties:
[source,bash]
----
java -Djavax.net.ssl.trustStore=/path/to/truststore.jks \
     -Djavax.net.ssl.trustStorePassword=password \
     -jar my-app.jar
----

==== Problem: Kafka SerDes fails with "Schema not found"

*Cause:* Schema auto-registration disabled or failed.

*Solution:*

Enable auto-registration:
[source,properties]
----
apicurio.registry.auto-register=true
----

Check registry logs for registration errors:
[source,bash]
----
docker logs registry-v3 | grep "artifact registration"
----

=== Performance Issues

==== Problem: v3 slower than v2

*Cause:* Various possible causes.

*Investigation:*

1. Check database connection pool size
2. Verify Kafka topic partition count (KafkaSQL)
3. Review JVM heap settings
4. Check for index creation on database

*Solution:*
[source,properties]
----
# Increase connection pool
APICURIO_DATASOURCE_POOL_MAX_SIZE=20

# Increase JVM heap
JAVA_OPTS="-Xmx2g -Xms2g"
----

=== Rollback Scenarios

==== Problem: Need to rollback after several hours on v3

*Challenge:* New data created in v3 since migration.

*Solution Options:*

1. Export from v3 and import to v2 (if compatible)
2. Accept data loss of new artifacts
3. Fix v3 issues and remain on v3 (preferred)

=== Getting Help

If you encounter issues not covered here:

1. Check Registry logs: `docker logs registry-v3`
2. Enable debug logging: `QUARKUS_LOG_LEVEL=DEBUG`
3. Review migration baseline files for comparison
4. Contact Apicurio support with:
   - Migration steps performed
   - Error messages and logs
   - Configuration files (redact secrets)
   - Export/import file sizes
----

== Recommended Document Structure

Based on the analysis, here's the recommended reorganization of the migration guide:

[source,asciidoc]
----
1. Introduction
   - Overview of changes in 3.x
   - Breaking changes summary
   - Migration approach overview

2. **NEW: Migration Planning**
   - Downtime expectations and minimization
   - Resource requirements (v2 + v3 running simultaneously)
   - Risk assessment
   - Rollback strategy

3. **NEW: Complete Migration Workflow**
   - Step-by-step integrated procedure
   - Phase-based approach with checkpoints

4. Migrating Registry Data (ENHANCED)
   - Export/import procedures (with authentication)
   - KafkaSQL-specific migration guidance
   - Validation procedures (pre and post)
   - Data integrity verification

5. Migrating Client Applications (ENHANCED)
   - Kafka SerDes migration (significantly expanded)
   - TLS/HTTPS configuration changes
   - Backward compatibility testing
   - Gradual migration approach

6. Updating Registry Configuration (ENHANCED)
   - Complete property mapping tables (scenario-validated)
   - Storage-specific configuration
   - Authentication configuration
   - Common pitfalls and corrections

7. **NEW: Post-Migration Validation**
   - Comprehensive validation checklist
   - Backward compatibility testing
   - Native v3 functionality testing
   - Performance validation

8. **NEW: Rollback Procedures**
   - When to rollback
   - Immediate rollback steps
   - Delayed rollback considerations
   - Data loss scenarios

9. **NEW: Troubleshooting**
   - Common issues and solutions
   - Export/import problems
   - Authentication errors
   - Configuration mistakes
   - Performance issues

10. Additional Resources
    - Links to detailed documentation
    - API reference
    - Community support
----

== Summary of Key Findings

=== Critical Missing Content

1. **Downtime management and load balancer usage** - Scenarios show 30-second downtime is achievable; guide implies
   longer downtime
2. **Read-only mode during export** - Critical for data consistency; v2 lacks built-in read-only mode, must use nginx
   to block write operations (POST/PUT/DELETE) during export
3. **Pre/post migration validation** - Scenarios have comprehensive validation; guide only mentions artifact count
4. **Authentication during export/import** - Scenarios use OAuth2; guide examples are unauthenticated
5. **KafkaSQL migration specifics** - Scenarios show export/import is REQUIRED; guide doesn't clarify this
6. **Complete configuration mappings** - Scenarios reveal properties missing from guide tables
7. **Kafka SerDes migration** - Scenarios demonstrate full workflow; guide has one sentence

=== Accuracy Issues

1. Line 31: "Re-engineered Kafka storage variant" - should clarify this is "KafkaSQL storage"
2. Configuration tables incomplete (missing properties used in scenarios)
3. Authentication property mappings incomplete (AUTH_ENABLED, KEYCLOAK_URL not documented)

=== Usability Concerns

1. No integrated workflow - three separate sections don't show how they fit together
2. No time estimates for migration phases
3. No troubleshooting guidance
4. No rollback procedure
5. Missing validation checklist

== Implementation Priority

=== Immediate (Critical for Success)

1. **Add read-only mode strategy** - Prevent data changes during export using nginx method blocking
2. Add complete migration workflow with phases
3. Add authentication examples to export/import
4. Complete configuration property tables
5. Add KafkaSQL migration specifics
6. Add validation procedures

=== High (Strongly Recommended)

7. Expand Kafka SerDes migration section
8. Add downtime minimization guidance
9. Add rollback procedures
10. Add TLS configuration during migration

=== Medium (Improves Experience)

11. Add troubleshooting section
12. Add time estimates
13. Add diagrams for architecture
14. Add validation checklists

== Conclusion

The four migration scenarios are **excellent** and demonstrate production-ready patterns that customers would greatly
benefit from. The migration guide should be enhanced to reflect the proven procedures demonstrated in these scenarios.

The scenarios reveal that a well-planned migration can be executed with minimal downtime (~30 seconds), comprehensive
validation, and safe rollback capability. This story should be clearly communicated in the migration guide to give
customers confidence in the migration process.

*Estimated effort to implement recommendations:* 2-3 days of technical writing, incorporating scenario learnings and
expanding existing sections.

*Impact of improvements:* Significantly reduced customer migration failures, reduced support burden, increased
confidence in the 3.x release, better customer experience.
