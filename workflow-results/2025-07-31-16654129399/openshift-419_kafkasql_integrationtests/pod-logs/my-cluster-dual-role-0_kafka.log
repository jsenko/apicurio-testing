STRIMZI_BROKER_ID=0
Preparing truststore for replication listener
Adding /opt/kafka/cluster-ca-certs/ca.crt to truststore /tmp/kafka/cluster.truststore.p12 with alias ca
Certificate was added to keystore
Preparing truststore for replication listener is complete
Looking for the CA matching the server certificate
CA matching the server certificate found: /opt/kafka/cluster-ca-certs/ca.crt
Preparing keystore for replication and clienttls listener
Preparing keystore for replication and clienttls listener is complete
Preparing truststore for client authentication
Adding /opt/kafka/client-ca-certs/ca.crt to truststore /tmp/kafka/clients.truststore.p12 with alias ca
Certificate was added to keystore
Preparing truststore for client authentication is complete
Starting Kafka with configuration:
##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Node ID
##########
node.id=0

##########
# KRaft configuration
##########
process.roles=broker,controller
controller.listener.names=CONTROLPLANE-9090
controller.quorum.voters=0@my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090

##########
# KRaft metadata log dir configuration
##########
metadata.log.dir=/var/lib/kafka/data-0/kafka-log0

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data-0/kafka-log0

##########
# Control Plane listener
##########
listener.name.controlplane-9090.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.controlplane-9090.ssl.keystore.password=[hidden]
listener.name.controlplane-9090.ssl.keystore.type=PKCS12
listener.name.controlplane-9090.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.controlplane-9090.ssl.truststore.password=[hidden]
listener.name.controlplane-9090.ssl.truststore.type=PKCS12
listener.name.controlplane-9090.ssl.client.auth=required

##########
# Replication listener
##########
listener.name.replication-9091.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.replication-9091.ssl.keystore.password=[hidden]
listener.name.replication-9091.ssl.keystore.type=PKCS12
listener.name.replication-9091.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12
listener.name.replication-9091.ssl.truststore.password=[hidden]
listener.name.replication-9091.ssl.truststore.type=PKCS12
listener.name.replication-9091.ssl.client.auth=required

##########
# Listener configuration: PLAIN-9092
##########

##########
# Listener configuration: TLS-9093
##########
listener.name.tls-9093.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12
listener.name.tls-9093.ssl.keystore.password=[hidden]
listener.name.tls-9093.ssl.keystore.type=PKCS12


##########
# Common listener configuration
##########
listener.security.protocol.map=CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
listeners=CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
inter.broker.listener.name=REPLICATION-9091
advertised.listeners=CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9093
sasl.enabled.mechanisms=
ssl.endpoint.identification.algorithm=HTTPS

##########
# Config providers
##########
# Configuration providers configured by the user and by Strimzi
config.providers=strimzienv,strimzifile,strimzidir
config.providers.strimzienv.class=org.apache.kafka.common.config.provider.EnvVarConfigProvider
config.providers.strimzienv.param.allowlist.pattern=.*
config.providers.strimzifile.class=org.apache.kafka.common.config.provider.FileConfigProvider
config.providers.strimzifile.param.allowed.paths=/opt/kafka
config.providers.strimzidir.class=org.apache.kafka.common.config.provider.DirectoryConfigProvider
config.providers.strimzidir.param.allowed.paths=/opt/kafka

##########
# User provided configuration
##########
default.replication.factor=1
min.insync.replicas=1
offsets.topic.replication.factor=1
transaction.state.log.min.isr=1
transaction.state.log.replication.factor=1
Making sure the Kraft storage is formatted with cluster ID n7nVFXOZTAGHwPpkWIh1lQ and metadata version 4.0-IV3
2025-07-31 16:56:10 INFO  [main] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2025-07-31 16:56:10 INFO  [main] AbstractConfig:371 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 10
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

Formatting metadata directory /var/lib/kafka/data-0/kafka-log0 with metadata.version 4.0-IV3.
KRaft storage formatting is done

Preparing Kafka Agent configuration

+ exec /usr/bin/tini -w -e 143 -- /opt/kafka/bin/kafka-server-start.sh /tmp/strimzi.properties
2025-07-31 16:56:11 INFO  [main] KafkaAgent:342 - Starting KafkaAgent with sslKeyStorePath=/tmp/kafka/cluster.keystore.p12 and sslTrustStore=/tmp/kafka/cluster.truststore.p12
2025-07-31 16:56:12 INFO  [main] Server:553 - jetty-12.0.15; built: 2024-11-05T19:44:57.623Z; git: 8281ae9740d4b4225e8166cc476bad237c70213a; jvm 17.0.15+6-LTS
2025-07-31 16:56:12 INFO  [main] ContextHandler:756 - Started oejsh.ContextHandler@1b8a29df{/v1/broker-state,/v1/broker-state,b=null,a=AVAILABLE,h=iska.KafkaAgent$@12a94400{STARTED}}
2025-07-31 16:56:12 INFO  [main] ContextHandler:756 - Started oejsh.ContextHandler@6a47b187{/v1/ready,/v1/ready,b=null,a=AVAILABLE,h=iska.KafkaAgent$@2049a9c1{STARTED}}
2025-07-31 16:56:12 INFO  [main] SslContextFactory:337 - x509=X509@6f63b475(my-cluster-dual-role-0,h=[my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local, my-cluster-kafka-brokers.kafkasql.svc, my-cluster-kafka-brokers.kafkasql, my-cluster-kafka-brokers.kafkasql.svc.cluster.local, my-cluster-kafka-bootstrap, my-cluster-kafka-bootstrap.kafkasql.svc, my-cluster-kafka-brokers, my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc, my-cluster-kafka-bootstrap.kafkasql, my-cluster-kafka-bootstrap.kafkasql.svc.cluster.local, my-cluster-kafka],a=[],w=[]) for Server@554e218[provider=null,keyStore=file:///tmp/kafka/cluster.keystore.p12,trustStore=file:///tmp/kafka/cluster.truststore.p12]
2025-07-31 16:56:12 INFO  [main] AbstractConnector:326 - Started ServerConnector@3b65d1b0{SSL, (ssl, http/1.1)}{0.0.0.0:8443}
2025-07-31 16:56:12 INFO  [main] AbstractConnector:326 - Started ServerConnector@37f4a948{HTTP/1.1, (http/1.1)}{localhost:8080}
2025-07-31 16:56:12 INFO  [main] Server:610 - Started oejs.Server@4f4c4b1a{STARTING}[12.0.15,sto=30000] @1188ms
2025-07-31 16:56:12 INFO  [main] KafkaAgent:120 - Starting metrics registry
2025-07-31 16:56:12 INFO  [main] KafkaAgent:156 - Found class org.apache.kafka.server.metrics.KafkaYammerMetrics for Kafka 3.3 and newer.
2025-07-31 16:56:12 INFO  [main] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2025-07-31 16:56:12 INFO  [main] LoggingSignalHandler:72 - Registered signal handlers for TERM, INT, HUP
2025-07-31 16:56:12 INFO  [main] ControllerServer:66 - [ControllerServer id=0] Starting controller
2025-07-31 16:56:13 INFO  [main] ConnectionQuotas:66 - Updated connection-accept-rate max connection creation rate to 2147483647
2025-07-31 16:56:13 INFO  [main] SocketServer:66 - [SocketServer listenerType=CONTROLLER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLPLANE-9090)
2025-07-31 16:56:13 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint CONTROLPLANE-9090. Endpoint is now READY.
2025-07-31 16:56:13 INFO  [main] SharedServer:66 - [SharedServer id=0] Starting SharedServer
2025-07-31 16:56:13 INFO  [main] UnifiedLog:73 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:13 INFO  [main] UnifiedLog:97 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Reloading from producer snapshot and rebuilding producer state from offset 0
2025-07-31 16:56:13 INFO  [main] UnifiedLog:133 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0
2025-07-31 16:56:13 INFO  [main] KafkaMetadataLog$:575 - Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data-0/kafka-log0/__cluster_metadata-0
2025-07-31 16:56:13 INFO  [raft-expiration-reaper] TimingWheelExpirationService$ExpiredOperationReaper:133 - [raft-expiration-reaper]: Starting
2025-07-31 16:56:13 INFO  [main] KafkaRaftClient:490 - [RaftManager id=0] Reading KRaft snapshot and log as part of the initialization
2025-07-31 16:56:13 INFO  [main] KafkaRaftClient:492 - [RaftManager id=0] Starting voters are VoterSet(voters={0=VoterNode(voterKey=ReplicaKey(id=0, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLPLANE-9090)=my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local/10.128.2.18:9090}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])})
2025-07-31 16:56:13 INFO  [main] KafkaRaftClient:518 - [RaftManager id=0] Starting request manager with static voters: [my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)]
2025-07-31 16:56:13 INFO  [main] QuorumState:739 - [RaftManager id=0] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1843, highWatermark=Optional.empty) from null
2025-07-31 16:56:13 INFO  [main] QuorumState:756 - [RaftManager id=0] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1843, highWatermark=Optional.empty) from null
2025-07-31 16:56:13 INFO  [main] QuorumState:756 - [RaftManager id=0] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1266, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1843, highWatermark=Optional.empty)
2025-07-31 16:56:13 INFO  [main] QuorumState:739 - [RaftManager id=0] Attempting durable transition to CandidateState(localId=0, localDirectoryId=Ts_1omYzmqtZpShZjbo2GA, epoch=1, retries=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1648) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1266, highWatermark=Optional.empty)
2025-07-31 16:56:13 INFO  [main] QuorumState:756 - [RaftManager id=0] Completed transition to CandidateState(localId=0, localDirectoryId=Ts_1omYzmqtZpShZjbo2GA, epoch=1, retries=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1648) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1266, highWatermark=Optional.empty)
2025-07-31 16:56:13 INFO  [main] QuorumState:739 - [RaftManager id=0] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=0, directoryId=Ts_1omYzmqtZpShZjbo2GA), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=Ts_1omYzmqtZpShZjbo2GA, epoch=1, retries=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1648)
2025-07-31 16:56:13 INFO  [main] QuorumState:756 - [RaftManager id=0] Completed transition to Leader(localReplicaKey=ReplicaKey(id=0, directoryId=Ts_1omYzmqtZpShZjbo2GA), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=Ts_1omYzmqtZpShZjbo2GA, epoch=1, retries=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1648)
2025-07-31 16:56:13 INFO  [kafka-0-raft-outbound-request-thread] KafkaNetworkChannel$SendThread:133 - [kafka-0-raft-outbound-request-thread]: Starting
2025-07-31 16:56:13 INFO  [kafka-0-raft-io-thread] KafkaRaftClientDriver:133 - [kafka-0-raft-io-thread]: Starting
2025-07-31 16:56:13 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:233 - [MetadataLoader id=0] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet.
2025-07-31 16:56:13 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for controller quorum voters future
2025-07-31 16:56:13 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for controller quorum voters future
2025-07-31 16:56:14 INFO  [kafka-0-raft-io-thread] LeaderState:539 - [RaftManager id=0] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)]
2025-07-31 16:56:14 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:3355 - [RaftManager id=0] Registered the listener org.apache.kafka.image.loader.MetadataLoader@220067832
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task writeNoOpRecord to run every 500 ms
2025-07-31 16:56:14 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:404 - [RaftManager id=0] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@220067832 to 0 since there are no snapshots
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task maybeFenceStaleBroker to run every 1125 ms
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task electPreferred to run every 300000 ms
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task electUnclean to run every 300000 ms
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task expireDelegationTokens to run every 3600000 ms
2025-07-31 16:56:14 INFO  [main] PeriodicTaskControlManager:168 - [QuorumController id=0] Registering periodic task generatePeriodicPerformanceMessage to run every 60000 ms
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:243 - [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2025-07-31 16:56:14 INFO  [main] QuorumController:1631 - [QuorumController id=0] Creating new QuorumController with clusterId n7nVFXOZTAGHwPpkWIh1lQ
2025-07-31 16:56:14 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:3355 - [RaftManager id=0] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@146378395
2025-07-31 16:56:14 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:404 - [RaftManager id=0] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@146378395 to 0 since there are no snapshots
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] QuorumController:1095 - [QuorumController id=0] Becoming the active controller at epoch 1, next write offset 1.
2025-07-31 16:56:14 INFO  [controller-0-ThrottledChannelReaper-Fetch] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Fetch]: Starting
2025-07-31 16:56:14 INFO  [controller-0-ThrottledChannelReaper-Produce] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Produce]: Starting
2025-07-31 16:56:14 INFO  [controller-0-ThrottledChannelReaper-Request] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Request]: Starting
2025-07-31 16:56:14 INFO  [controller-0-ThrottledChannelReaper-ControllerMutation] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-ControllerMutation]: Starting
2025-07-31 16:56:14 WARN  [quorum-controller-0-event-handler] QuorumController:105 - [QuorumController id=0] Performing controller activation. The metadata log appears to be empty. Appending 3 bootstrap record(s) in metadata transaction at metadata.version 4.0-IV3 from bootstrap source 'the binary bootstrap metadata file: /var/lib/kafka/data-0/kafka-log0/bootstrap.checkpoint'.
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] OffsetControlManager:392 - [QuorumController id=0] Replayed BeginTransactionRecord(name='Bootstrap records') at offset 1.
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] FeatureControlManager:372 - [QuorumController id=0] Replayed a FeatureLevelRecord setting metadata.version to 4.0-IV3
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] FeatureControlManager:383 - [QuorumController id=0] Replayed a FeatureLevelRecord setting feature group.version to 1
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] FeatureControlManager:383 - [QuorumController id=0] Replayed a FeatureLevelRecord setting feature transaction.version to 2
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] OffsetControlManager:404 - [QuorumController id=0] Replayed EndTransactionRecord() at offset 5.
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:232 - [QuorumController id=0] Activated periodic tasks: electPreferred, electUnclean, expireDelegationTokens, generatePeriodicPerformanceMessage, maybeFenceStaleBroker, writeNoOpRecord
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:247 - [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 6
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for the controller metadata publishers to be installed
2025-07-31 16:56:14 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for the controller metadata publishers to be installed
2025-07-31 16:56:14 INFO  [main] SocketServer:66 - [SocketServer listenerType=CONTROLLER, nodeId=0] Enabling request processing.
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] FeaturesPublisher:63 - [ControllerServer id=0] Loaded new metadata Features(metadataVersion=4.0-IV3, finalizedFeatures={group.version=1, transaction.version=2, metadata.version=25}, finalizedFeaturesEpoch=5).
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [main] DataPlaneAcceptor:66 - Awaiting socket connections on 0.0.0.0:9090.
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ScramPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing AclPublisher controller id=0 with a snapshot at offset 5
2025-07-31 16:56:14 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:66 - [ControllerRegistrationManager id=0 incarnation=byae2zZxSwGMlGSXnIYR1g] initialized channel manager.
2025-07-31 16:56:14 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for all of the authorizer futures to be completed
2025-07-31 16:56:14 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for all of the authorizer futures to be completed
2025-07-31 16:56:14 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2025-07-31 16:56:14 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2025-07-31 16:56:14 INFO  [main] BrokerServer:66 - [BrokerServer id=0] Transition from SHUTDOWN to STARTING
2025-07-31 16:56:14 INFO  [main] BrokerServer:66 - [BrokerServer id=0] Starting broker
2025-07-31 16:56:14 INFO  [controller-0-to-controller-registration-channel-manager] NodeToControllerRequestThread:133 - [controller-0-to-controller-registration-channel-manager]: Starting
2025-07-31 16:56:14 INFO  [controller-0-to-controller-registration-channel-manager] NodeToControllerRequestThread:66 - [controller-0-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2025-07-31 16:56:14 INFO  [broker-0-ThrottledChannelReaper-Fetch] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Fetch]: Starting
2025-07-31 16:56:14 INFO  [broker-0-ThrottledChannelReaper-Produce] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Produce]: Starting
2025-07-31 16:56:14 INFO  [broker-0-ThrottledChannelReaper-Request] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Request]: Starting
2025-07-31 16:56:14 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:66 - [ControllerRegistrationManager id=0 incarnation=byae2zZxSwGMlGSXnIYR1g] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=0, incarnationId=byae2zZxSwGMlGSXnIYR1g, zkMigrationReady=false, listeners=[Listener(name='CONTROLPLANE-9090', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc', port=9090, securityProtocol=1)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)])
2025-07-31 16:56:14 INFO  [broker-0-ThrottledChannelReaper-ControllerMutation] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-ControllerMutation]: Starting
2025-07-31 16:56:14 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for controller quorum voters future
2025-07-31 16:56:14 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for controller quorum voters future
2025-07-31 16:56:14 INFO  [broker-0-to-controller-forwarding-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-forwarding-channel-manager]: Starting
2025-07-31 16:56:14 INFO  [broker-0-to-controller-forwarding-channel-manager] NodeToControllerRequestThread:66 - [broker-0-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2025-07-31 16:56:14 INFO  [client-metrics-reaper] SystemTimerReaper$Reaper:133 - [client-metrics-reaper]: Starting
2025-07-31 16:56:14 INFO  [main] ConnectionQuotas:66 - Updated connection-accept-rate max connection creation rate to 2147483647
2025-07-31 16:56:14 INFO  [quorum-controller-0-event-handler] ClusterControlManager:683 - [QuorumController id=0] Replayed RegisterControllerRecord containing ControllerRegistration(id=0, incarnationId=byae2zZxSwGMlGSXnIYR1g, zkMigrationReady=false, listeners=[Endpoint(listenerName='CONTROLPLANE-9090', securityProtocol=SSL, host='my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc', port=9090)], supportedFeatures={eligible.leader.replicas.version: 0-1, group.version: 0-1, kraft.version: 0-1, metadata.version: 7-25, transaction.version: 0-2}).
2025-07-31 16:56:14 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:66 - [ControllerRegistrationManager id=0 incarnation=byae2zZxSwGMlGSXnIYR1g] Our registration has been persisted to the metadata log.
2025-07-31 16:56:14 INFO  [controller-0-to-controller-registration-channel-manager] ControllerRegistrationManager:66 - [ControllerRegistrationManager id=0 incarnation=byae2zZxSwGMlGSXnIYR1g] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest.
2025-07-31 16:56:14 INFO  [main] SocketServer:66 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(REPLICATION-9091)
2025-07-31 16:56:14 INFO  [main] ConnectionQuotas:66 - Updated connection-accept-rate max connection creation rate to 2147483647
2025-07-31 16:56:14 INFO  [main] SocketServer:66 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAIN-9092)
2025-07-31 16:56:14 INFO  [main] ConnectionQuotas:66 - Updated connection-accept-rate max connection creation rate to 2147483647
2025-07-31 16:56:14 INFO  [main] SocketServer:66 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(TLS-9093)
2025-07-31 16:56:14 INFO  [broker-0-to-controller-alter-partition-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-alter-partition-channel-manager]: Starting
2025-07-31 16:56:14 INFO  [broker-0-to-controller-alter-partition-channel-manager] NodeToControllerRequestThread:66 - [broker-0-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2025-07-31 16:56:14 INFO  [broker-0-to-controller-directory-assignments-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-directory-assignments-channel-manager]: Starting
2025-07-31 16:56:14 INFO  [broker-0-to-controller-directory-assignments-channel-manager] NodeToControllerRequestThread:66 - [broker-0-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:14 INFO  [main] BrokerServer:66 - [BrokerServer id=0] Using no op persister
2025-07-31 16:56:14 INFO  [group-coordinator-reaper] SystemTimerReaper$Reaper:133 - [group-coordinator-reaper]: Starting
2025-07-31 16:56:14 INFO  [group-coordinator-event-processor-1] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-1]: Starting
2025-07-31 16:56:14 INFO  [group-coordinator-event-processor-2] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-2]: Starting
2025-07-31 16:56:14 INFO  [group-coordinator-event-processor-0] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-0]: Starting
2025-07-31 16:56:14 INFO  [group-coordinator-event-processor-3] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-3]: Starting
2025-07-31 16:56:14 INFO  [main] LogManager:66 - Unable to read the broker epoch in /var/lib/kafka/data-0/kafka-log0.
2025-07-31 16:56:14 INFO  [broker-0-to-controller-heartbeat-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-heartbeat-channel-manager]: Starting
2025-07-31 16:56:14 INFO  [broker-0-to-controller-heartbeat-channel-manager] NodeToControllerRequestThread:66 - [broker-0-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2025-07-31 16:56:14 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:66 - [BrokerLifecycleManager id=0] Incarnation _KQ0bAWCTUGbNFBu0S6soA of broker 0 in cluster n7nVFXOZTAGHwPpkWIh1lQ is now STARTING.
2025-07-31 16:56:14 INFO  [share-group-lock-timeout-reaper] SystemTimerReaper$Reaper:133 - [share-group-lock-timeout-reaper]: Starting
2025-07-31 16:56:15 INFO  [ExpirationReaper-0-null] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-null]: Starting
2025-07-31 16:56:15 INFO  [quorum-controller-0-event-handler] ClusterControlManager:429 - [QuorumController id=0] No previous registration found for broker 0. New incarnation ID is _KQ0bAWCTUGbNFBu0S6soA.  Generated 0 record(s) to clean up previous incarnations. New broker epoch is 8.
2025-07-31 16:56:15 INFO  [quorum-controller-0-event-handler] ClusterControlManager:570 - [QuorumController id=0] Replayed initial RegisterBrokerRecord for broker 0: RegisterBrokerRecord(brokerId=0, isMigratingZkBroker=false, incarnationId=_KQ0bAWCTUGbNFBu0S6soA, brokerEpoch=8, endPoints=[BrokerEndpoint(name='REPLICATION-9091', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc', port=9091, securityProtocol=1), BrokerEndpoint(name='PLAIN-9092', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc', port=9092, securityProtocol=0), BrokerEndpoint(name='TLS-9093', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc', port=9093, securityProtocol=1)], features=[BrokerFeature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), BrokerFeature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[Ts_1omYzmqtZpShZjbo2GA])
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing MetadataVersionPublisher(id=0) with a snapshot at offset 7
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 7
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] BrokerMetadataPublisher:66 - [BrokerMetadataPublisher id=0] Publishing initial metadata at offset OffsetAndEpoch(offset=7, epoch=1) with metadata.version Optional[4.0-IV3].
2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the broker metadata publishers to be installed
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data-0/kafka-log0)
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the broker metadata publishers to be installed
2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the controller to acknowledge that we are caught up
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - No logs found to be loaded in /var/lib/kafka/data-0/kafka-log0
2025-07-31 16:56:15 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:66 - [BrokerLifecycleManager id=0] Successfully registered broker 0 with broker epoch 8
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Loaded 0 logs in 17ms
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] LogCleaner:66 - Starting the log cleaner
2025-07-31 16:56:15 INFO  [kafka-log-cleaner-thread-0] LogCleaner$CleanerThread:133 - [kafka-log-cleaner-thread-0]: Starting
2025-07-31 16:56:15 INFO  [LogDirFailureHandler] ReplicaManager$LogDirFailureHandler:133 - [LogDirFailureHandler]: Starting
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] GroupCoordinatorService:1208 - [GroupCoordinator id=0] Starting up.
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] GroupCoordinatorService:1211 - [GroupCoordinator id=0] Startup complete.
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2025-07-31 16:56:15 INFO  [AddPartitionsToTxnSenderThread-0] AddPartitionsToTxnManager:133 - [AddPartitionsToTxnSenderThread-0]: Starting
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2025-07-31 16:56:15 INFO  [TxnMarkerSenderThread-0] TransactionMarkerChannelManager:133 - [TxnMarkerSenderThread-0]: Starting
2025-07-31 16:56:15 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=0) with a snapshot at offset 7
2025-07-31 16:56:15 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:66 - [BrokerLifecycleManager id=0] The broker has caught up. Transitioning from STARTING to RECOVERY.
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the controller to acknowledge that we are caught up
2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the initial broker metadata update to be published
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the initial broker metadata update to be published
2025-07-31 16:56:15 INFO  [main] AbstractConfig:371 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.kafkasql.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 10
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the broker to be unfenced
2025-07-31 16:56:15 INFO  [quorum-controller-0-event-handler] BrokerHeartbeatManager:413 - [QuorumController id=0] The request from broker 0 to unfence has been granted because it has caught up with the offset of its register broker record 8.
2025-07-31 16:56:15 INFO  [quorum-controller-0-event-handler] ClusterControlManager:662 - [QuorumController id=0] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 0: BrokerRegistrationChangeRecord(brokerId=0, brokerEpoch=8, fenced=-1, inControlledShutdown=0, logDirs=[])
2025-07-31 16:56:15 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:66 - [BrokerLifecycleManager id=0] The broker has been unfenced. Transitioning from RECOVERY to RUNNING.
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the broker to be unfenced
2025-07-31 16:56:15 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint TLS-9093. Endpoint is now READY.
2025-07-31 16:56:15 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint PLAIN-9092. Endpoint is now READY.
2025-07-31 16:56:15 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint REPLICATION-9091. Endpoint is now READY.
2025-07-31 16:56:15 INFO  [main] SocketServer:66 - [SocketServer listenerType=BROKER, nodeId=0] Enabling request processing.
2025-07-31 16:56:15 INFO  [main] DataPlaneAcceptor:66 - Awaiting socket connections on 0.0.0.0:9091.
2025-07-31 16:56:15 INFO  [main] DataPlaneAcceptor:66 - Awaiting socket connections on 0.0.0.0:9093.
2025-07-31 16:56:15 INFO  [main] DataPlaneAcceptor:66 - Awaiting socket connections on 0.0.0.0:9092.
2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for all of the authorizer futures to be completed
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for all of the authorizer futures to be completed
2025-07-31 16:56:15 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2025-07-31 16:56:15 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2025-07-31 16:56:15 INFO  [main] BrokerServer:66 - [BrokerServer id=0] Transition from STARTING to STARTED
2025-07-31 16:56:15 INFO  [main] AppInfoParser:125 - Kafka version: 4.0.0
2025-07-31 16:56:15 INFO  [main] AppInfoParser:126 - Kafka commitId: 985bc99521dd22bb
2025-07-31 16:56:15 INFO  [main] AppInfoParser:127 - Kafka startTimeMs: 1753980975251
2025-07-31 16:56:15 INFO  [main] KafkaRaftServer:66 - [KafkaRaftServer nodeId=0] Kafka Server started
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:702 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='kafkasql-journal', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='min.insync.replicas', value='1')]): SUCCESS, CreatableTopic(name='kafkasql-snapshots', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='min.insync.replicas', value='1')]): SUCCESS, CreatableTopic(name='registry-events', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='min.insync.replicas', value='1')]): SUCCESS
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:437 - [QuorumController id=0] Replayed TopicRecord for topic kafkasql-journal with topic ID JK16eT1xSNKNd7UlY-oCZQ.
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-journal') which set configuration min.insync.replicas to 1
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition kafkasql-journal-0 with topic ID JK16eT1xSNKNd7UlY-oCZQ and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:437 - [QuorumController id=0] Replayed TopicRecord for topic kafkasql-snapshots with topic ID CRSMBX4ER7-1frIuRtN6UQ.
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-snapshots') which set configuration min.insync.replicas to 1
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition kafkasql-snapshots-0 with topic ID CRSMBX4ER7-1frIuRtN6UQ and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:437 - [QuorumController id=0] Replayed TopicRecord for topic registry-events with topic ID H2tErRI8T062Nx1sdNhMyg.
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='registry-events') which set configuration min.insync.replicas to 1
2025-07-31 16:56:31 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition registry-events-0 with topic ID H2tErRI8T062Nx1sdNhMyg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Transitioning 3 partition(s) to local leaders.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafkasql-snapshots-0, kafkasql-journal-0, registry-events-0)
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition kafkasql-snapshots-0 with topic id CRSMBX4ER7-1frIuRtN6UQ.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=kafkasql-snapshots-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition kafkasql-snapshots-0 in /var/lib/kafka/data-0/kafka-log0/kafkasql-snapshots-0 with properties {min.insync.replicas=1}
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition kafkasql-snapshots-0 broker=0] No checkpointed highwatermark is found for partition kafkasql-snapshots-0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition kafkasql-snapshots-0 broker=0] Log loaded for partition kafkasql-snapshots-0 with initial high watermark 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader kafkasql-snapshots-0 with topic id Some(CRSMBX4ER7-1frIuRtN6UQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition kafkasql-journal-0 with topic id JK16eT1xSNKNd7UlY-oCZQ.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=kafkasql-journal-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition kafkasql-journal-0 in /var/lib/kafka/data-0/kafka-log0/kafkasql-journal-0 with properties {min.insync.replicas=1}
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition kafkasql-journal-0 broker=0] No checkpointed highwatermark is found for partition kafkasql-journal-0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition kafkasql-journal-0 broker=0] Log loaded for partition kafkasql-journal-0 with initial high watermark 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader kafkasql-journal-0 with topic id Some(JK16eT1xSNKNd7UlY-oCZQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition registry-events-0 with topic id H2tErRI8T062Nx1sdNhMyg.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=registry-events-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition registry-events-0 in /var/lib/kafka/data-0/kafka-log0/registry-events-0 with properties {min.insync.replicas=1}
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition registry-events-0 broker=0] No checkpointed highwatermark is found for partition registry-events-0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition registry-events-0 broker=0] Log loaded for partition registry-events-0 with initial high watermark 0
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader registry-events-0 with topic id Some(H2tErRI8T062Nx1sdNhMyg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:66 - [DynamicConfigPublisher broker id=0] Updating topic kafkasql-journal with new configuration : min.insync.replicas -> 1
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:66 - [DynamicConfigPublisher broker id=0] Updating topic kafkasql-snapshots with new configuration : min.insync.replicas -> 1
2025-07-31 16:56:31 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:66 - [DynamicConfigPublisher broker id=0] Updating topic registry-events with new configuration : min.insync.replicas -> 1
2025-07-31 16:56:32 INFO  [data-plane-kafka-request-handler-3] DefaultAutoTopicCreationManager:66 - Sent auto-creation request for Set(__consumer_offsets) to the active controller.
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:702 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]): SUCCESS
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:437 - [QuorumController id=0] Replayed TopicRecord for topic __consumer_offsets with topic ID Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:530 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:451 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID Fie4SzmsSOOuCWrmI0cFDg and PartitionRegistration(replicas=[0], directories=[Ts_1omYzmqtZpShZjbo2GA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Transitioning 50 partition(s) to local leaders.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2)
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-13 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-13 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-13 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-46 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-46 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-46 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-9 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-9 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-9 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-42 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-42 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-42 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-21 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-21 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-21 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-17 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-17 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-17 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-30 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-30 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-30 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-26 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-26 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-26 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-5 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-5 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-5 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-38 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-38 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-38 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-1 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-1 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-1 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-34 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-34 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-34 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-16 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-16 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-16 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-45 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-45 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-45 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-12 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-12 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-12 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-41 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-41 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-41 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-24 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-24 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-24 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-20 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-20 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-20 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-49 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-49 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-49 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-0 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-0 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-0 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-29 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-29 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-29 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-25 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-25 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-25 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-8 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-8 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-8 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-37 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-37 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-37 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-4 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-4 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-4 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-33 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-33 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-33 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-15 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-15 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-15 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-48 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-48 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-48 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-11 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-11 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-11 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-44 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-44 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-44 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-23 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-23 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-23 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-19 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-19 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-19 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-32 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-32 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-32 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-28 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-28 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-28 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-7 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-7 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-7 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-40 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-40 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-40 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-3 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-3 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-3 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-36 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-36 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-36 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-47 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-47 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-47 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-14 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-14 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-14 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-43 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-43 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-43 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-10 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-10 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-10 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-22 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-22 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-22 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-18 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-18 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-18 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-31 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-31 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-31 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-27 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-27 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-27 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-39 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-39 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-39 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-6 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-6 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-6 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-35 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-35 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-35 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Creating new partition __consumer_offsets-2 with topic id Fie4SzmsSOOuCWrmI0cFDg.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:73 - [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] LogManager:66 - Created log for partition __consumer_offsets-2 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] Partition:66 - [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] logger:66 - [Broker id=0] Leader __consumer_offsets-2 with topic id Some(Fie4SzmsSOOuCWrmI0cFDg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-13 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-46 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-9 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-42 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-21 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-17 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-30 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-26 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-5 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-38 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-1 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-34 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-16 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-45 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-12 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-41 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-24 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-20 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-49 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-0 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-29 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-25 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-8 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-37 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-4 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-33 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-15 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-48 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-11 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-44 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-23 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-19 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-32 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-28 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-7 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-40 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-3 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-36 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-47 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-14 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-43 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-10 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-22 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-18 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-31 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-27 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-39 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-6 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-35 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2359 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-2 with epoch 0
2025-07-31 16:56:32 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:66 - [DynamicConfigPublisher broker id=0] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-14 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-7 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-3 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-47 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-29 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-26 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-46 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-30 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-43 with epoch 0 in 3ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-36 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-44 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-37 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-31 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-24 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-11 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-32 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-0 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-35 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-2 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-5 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-9 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-39 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-15 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-42 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-40 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-8 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-17 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-25 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-28 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-1 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-13 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-16 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-18 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-48 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-22 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-41 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-20 with epoch 0 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-21 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-10 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-12 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-4 with epoch 0 in 6ms where 6ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-27 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-33 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-38 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-45 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-23 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-34 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-19 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-6 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:714 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-49 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:4675 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Dynamic member with unknown member id joins group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b in Empty state. Created a new member id consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b and requesting the member to rejoin with this id.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:4745 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Pending dynamic member with id consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b joins group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b in Empty state. Adding to the group now.
2025-07-31 16:56:32 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:5237 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Preparing to rebalance group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b in state PreparingRebalance with old generation 0 (reason: Adding new member consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b with group instance id null; client reason: need to re-join with the given member-id: consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b).
2025-07-31 16:56:35 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:4947 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Stabilized group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b generation 1 with 1 members.
2025-07-31 16:56:45 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:4675 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Dynamic member with unknown member id joins group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b in Empty state. Created a new member id consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711 and requesting the member to rejoin with this id.
2025-07-31 16:56:45 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:4745 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Pending dynamic member with id consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711 joins group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b in Empty state. Adding to the group now.
2025-07-31 16:56:45 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:5237 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Preparing to rebalance group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b in state PreparingRebalance with old generation 0 (reason: Adding new member consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711 with group instance id null; client reason: need to re-join with the given member-id: consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711).
2025-07-31 16:56:48 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:4947 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Stabilized group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b generation 1 with 1 members.
2025-07-31 16:56:48 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:5706 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Assignment received from leader consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711 for group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b for generation 1. The group has 1 members, 0 of which are static.
2025-07-31 16:56:51 INFO  [quorum-controller-0-event-handler] ProducerIdControlManager:116 - [QuorumController id=0] Replaying ProducerIdsRecord ProducerIdsRecord(brokerId=0, brokerEpoch=8, nextProducerId=1000)
2025-07-31 16:56:51 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:4675 - [GroupCoordinator id=0 topic=__consumer_offsets partition=13] Dynamic member with unknown member id joins group apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea in Empty state. Created a new member id consumer-apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea-2-852abe84-5e85-4a66-a1c9-17c7c40e0280 and requesting the member to rejoin with this id.
2025-07-31 16:56:51 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:4745 - [GroupCoordinator id=0 topic=__consumer_offsets partition=13] Pending dynamic member with id consumer-apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea-2-852abe84-5e85-4a66-a1c9-17c7c40e0280 joins group apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea in Empty state. Adding to the group now.
2025-07-31 16:56:51 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:5237 - [GroupCoordinator id=0 topic=__consumer_offsets partition=13] Preparing to rebalance group apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea in state PreparingRebalance with old generation 0 (reason: Adding new member consumer-apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea-2-852abe84-5e85-4a66-a1c9-17c7c40e0280 with group instance id null; client reason: need to re-join with the given member-id: consumer-apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea-2-852abe84-5e85-4a66-a1c9-17c7c40e0280).
2025-07-31 16:56:54 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:4947 - [GroupCoordinator id=0 topic=__consumer_offsets partition=13] Stabilized group apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea generation 1 with 1 members.
2025-07-31 16:56:54 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:5706 - [GroupCoordinator id=0 topic=__consumer_offsets partition=13] Assignment received from leader consumer-apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea-2-852abe84-5e85-4a66-a1c9-17c7c40e0280 for group apicurio-7e9fe02d-de17-4e6d-8c83-ba4e44ea33ea for generation 1. The group has 1 members, 0 of which are static.
2025-07-31 16:57:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 342 controller events were completed, which took an average of 10.21 ms each. The slowest event was registerBroker(708628592), which took 46.23 ms.
2025-07-31 16:57:20 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:5031 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Member consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b in group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b has failed, removing it from the group.
2025-07-31 16:57:20 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:5237 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Preparing to rebalance group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b in state PreparingRebalance with old generation 1 (reason: removing member consumer-apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b-1-c5cd4d97-aff0-4ac5-a0ee-0f8ea6ed931b on heartbeat expiration.).
2025-07-31 16:57:20 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:4928 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Group apicurio-92a2daa2-936a-4649-8d0a-2f1d8c14f77b with generation 2 is now empty.
2025-07-31 16:58:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.73 ms each. The slowest event was writeNoOpRecord(287955112), which took 26.93 ms.
2025-07-31 16:59:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.63 ms each. The slowest event was writeNoOpRecord(647233802), which took 26.36 ms.
2025-07-31 17:00:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 325 controller events were completed, which took an average of 9.57 ms each. The slowest event was writeNoOpRecord(45968075), which took 27.07 ms.
2025-07-31 17:01:14 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:105 - [QuorumController id=0] Periodic task electPreferred generated 0 records in 395 microseconds.
2025-07-31 17:01:14 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:105 - [QuorumController id=0] Periodic task electUnclean generated 0 records in 22 microseconds.
2025-07-31 17:01:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 326 controller events were completed, which took an average of 9.51 ms each. The slowest event was writeNoOpRecord(931769282), which took 26.53 ms.
2025-07-31 17:01:50 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6319 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] [Group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b] Member consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711 has left group through explicit `LeaveGroup` request; client reason: consumer poll timeout has expired.
2025-07-31 17:01:50 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:5237 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Preparing to rebalance group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (consumer-apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b-1-049652da-1f25-4c15-97d6-634068079711) members.).
2025-07-31 17:01:50 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:4928 - [GroupCoordinator id=0 topic=__consumer_offsets partition=28] Group apicurio-d3c3a8b6-819c-4a1f-97fe-50be2048058b with generation 2 is now empty.
2025-07-31 17:02:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.55 ms each. The slowest event was writeNoOpRecord(2040303445), which took 30.63 ms.
2025-07-31 17:03:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 325 controller events were completed, which took an average of 9.48 ms each. The slowest event was writeNoOpRecord(183082516), which took 26.04 ms.
2025-07-31 17:04:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.49 ms each. The slowest event was writeNoOpRecord(1265652472), which took 25.69 ms.
2025-07-31 17:05:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.47 ms each. The slowest event was writeNoOpRecord(2079215844), which took 26.72 ms.
2025-07-31 17:06:14 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:105 - [QuorumController id=0] Periodic task electPreferred generated 0 records in 13 microseconds.
2025-07-31 17:06:14 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:105 - [QuorumController id=0] Periodic task electUnclean generated 0 records in 13 microseconds.
2025-07-31 17:06:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 327 controller events were completed, which took an average of 9.39 ms each. The slowest event was writeNoOpRecord(1841498602), which took 25.92 ms.
2025-07-31 17:06:14 INFO  [controller-0-to-controller-registration-channel-manager] NetworkClient:1072 - [NodeToControllerChannelManager id=0 name=registration] Node 0 disconnected.
2025-07-31 17:06:32 INFO  [group-coordinator-event-processor-1] GroupCoordinatorShard:671 - [GroupCoordinator id=0 topic=__consumer_offsets partition=9] Generated 1 tombstone records while cleaning up group metadata in 0 milliseconds.
2025-07-31 17:06:51 INFO  [broker-0-to-controller-forwarding-channel-manager] NetworkClient:1072 - [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected.
2025-07-31 17:07:14 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.47 ms each. The slowest event was writeNoOpRecord(1782541574), which took 26.01 ms.
